<h1>Chapter 5</h1><p class="chapter-subtitle"><span>Large Language Models to Identify Social Determinants of Health in Electronic Health Records </span></p><hr/><p><span>Shan Chen*</span><span>, Marco Guevara*, Spencer Thomas, Tafadzwa L. Chaunzwa, Idalid Franco, Benjamin H. Kann, Shalini Moningi, Jack M. Qian, Madeleine Goldstein, Susan Harper, </span></p><p><span>Hugo JWL Aerts, Paul J. Catalano, Guergana K. Savova, </span></p><p><span>Raymond H. Mak, Danielle S. Bitterman</span></p><p class="chapter-meta"><a href="https://doi.org/10.1038/s41746-023-00970-0" rel="noopener noreferrer" target="_blank"><em>npj Digital Medicine</em></a></p><h2>Summary</h2><p><span>Background<br/></span><span>SDoH strongly affect outcomes but are poorly captured in structured EHR data. LLMs could extract SDoH from clinical text, but sparse labels, class imbalance, and bias are challenges.</span></p><p><span>Methods<br/></span><span>We evaluated LLMs to extract six SDoH from notes (employment, housing, transportation, parental status, relationship, social support), testing fine-tuned Flan-T5 variants, synthetic-data augmentation, and zero-/few-shot ChatGPT-family baselines, plus a simple bias probe with injected demographics.</span></p><p><span>Findings<br/></span><span>Best models: Flan-T5 </span><span>XL</span><span> for any SDoH (macro-F1 </span><span>0.71</span><span>) and Flan-T5 </span><span>XXL</span><span> for adverse SDoH (macro-F1 </span><span>0.70</span><span>). Synthetic data helped smaller Flan-T5 models (</span><span>ΔF1 +0.12–+0.23</span><span>). Fine-tuned models beat ChatGPT-family zero-/few-shot, except </span><span>GPT-4 (10-shot)</span><span> on adverse SDoH. Fine-tuned models changed predictions less than ChatGPT when race/ethnicity or gender was injected (</span><span>p&lt;0.05</span><span>), indicating less algorithmic bias. At the patient level, models identified </span><span>93.8%</span><span> with adverse SDoH vs </span><span>2.0%</span><span> using ICD-10 Z-codes.</span></p><p><span>Interpretation<br/></span><span>Fine-tuned LLMs—augmented with synthetic text—can reliably surface SDoH from EHR notes, outperform general chat models and structured codes, and show lower bias, enabling better real-world evidence and targeted resource support.</span></p><h2>Introduction</h2><p><span>Health disparities have been extensively documented across medical specialties.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/j1dN+8yTi+Zp8L" rel="noopener noreferrer" target="_blank">1–3</a></sup></span><span> However, our ability to address these disparities remains limited due to an insufficient understanding of their contributing factors. Social determinants of health (SDoH), are defined by the World Health Organization as “the conditions in which people are born, grow, live, work, and age...shaped by the distribution of money, power, and resources at global, national, and local levels”. </span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/9pBzf" rel="noopener noreferrer" target="_blank">4</a></sup></span><span> SDoH may be adverse or protective, impacting health outcomes at multiple levels as they likely play a major role in disparities by determining access to and quality of medical care. For example, a patient cannot benefit from an effective treatment if they don’t have transportation to make it to the clinic. There is also emerging evidence that exposure to adverse SDoH may directly affect physical and mental health via inflammatory and neuro-endocrine changes.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/HoSYw+VXeKa+dQla1+zvwv7" rel="noopener noreferrer" target="_blank">5–8</a></sup></span><span> In fact, SDoH are estimated to account for 80-90% of modifiable factors impacting health outcomes.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/QlpcC" rel="noopener noreferrer" target="_blank">9</a></sup></span><span> </span></p><p><span>SDoH are rarely documented comprehensively in structured data in the electronic health records (EHRs),</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/NfPNB+HNP8d+xuWCW" rel="noopener noreferrer" target="_blank">10–12</a></sup></span><span> creating an obstacle to research and clinical care. Instead, issues related to SDoH are most frequently described in the free text of clinic notes, which creates a bottleneck for incorporating these critical factors into databases to research the full impact and drivers of SDoH, and for proactively identifying patients who may benefit from additional social work and resource support. </span></p><p><span>Natural language processing (NLP) could address these challenges by automating the abstraction of these data from clinical texts. Prior studies have demonstrated the feasibility of NLP for extracting a range of SDoH.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/dwSP+QKOo+3Z4R+tPmm+EfrS+v7vl+C5qx+ywEU+1P2G+XEymp+M3kyq" rel="noopener noreferrer" target="_blank">13–23</a></sup></span><span> Yet, there remains a need to optimize performance for the high-stakes medical domain and to evaluate state-of-the-art language models (LMs) for this task. In addition to anticipated performance changes scaling with model size, large LMs may support EHR mining via data augmentation. Across medical domains, data augmentation can boost performance and alleviate domain transfer issues and so is an especially promising approach for the nearly ubiquitous challenge of data scarcity in clinical NLP.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/OqrO+59gr+qGZf" rel="noopener noreferrer" target="_blank">24–26</a></sup></span><span> The advanced capabilities of state-of-the-art large LMs to generate coherent text open new avenues for data augmentation through synthetic text generation. However, the optimal methods for generating and utilizing such data remain uncertain. Large LM-generated synthetic data may also be a means to distill knowledge represented in larger LMs to more computationally accessible smaller LMs.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/PbaK" rel="noopener noreferrer" target="_blank">27</a></sup></span><span> In addition, few studies assess the potential bias of SDoH information extraction methods across patient populations. LMs could contribute to the health inequity crisis if they perform differently in diverse populations and/or recapitulate societal prejudices.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/RBOwB" rel="noopener noreferrer" target="_blank">28</a></sup></span><span> Therefore, understanding bias is critical for future development and deployment decisions.</span></p><p><span>Here, we characterize optimal methods, including the role of synthetic clinical text, for SDoH extraction using large language models. Specifically, we develop models to extract six key SDoH: employment status, housing issues, transportation issues, parental status, and social support. We investigate the value of incorporating large LM-generated synthetic SDoH data during the fine-tuning stage. We assess the performance of large LMs, including GPT3.5 and GPT4, in zero- and few-shot settings for identifying SDoH, and we explore the potential for algorithmic bias in LM predictions. Our methods could yield real-world evidence on SDoH, assist in identifying patients who could benefit from resource and social work support, and draw attention to the under-documented impact of social factors in health outcomes. </span></p><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image70.png" title=""/><figcaption>Fig. 1. Ablation studies: Performance in Macro-F1 of Flan-T5 XL models fine-tuned using gold data only (orange line) and gold and synthetic data (green line), as gold-labeled sentences are gradually reduced by undersample value from the training dataset for a) adverse social determinant of health (SDoH) mention task and b) any SDoH mention task. The full gold-labeled training set is comprised of 29,869 sentences, augmented with 1800 synthetic SDoH sentences, and tested on the in-domain radiotherapy(RT) test dataset.</figcaption></figure><h2>Results</h2><p><span>Model performance</span></p><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image14.png" title=""/><figcaption>Table 3 shows the performance of fine-tuned models for both SDoH tasks on the radiotherapy test set. The best-performing model for any SDoH mention task was Flan-T5 XXL (3 out of 6 categories) using synthetic data (Macro-F1 0.71). The best-performing model for the adverse SDoH mention task was Flan-T5 XL without synthetic data (macro-F1 0.70). In general, the Flan-T5 models outperformed BERT, and model performance scaled with size. However, although the Flan-T5 XL and XXL models were the largest models evaluated in terms of total parameters, because LoRA was used for their fine-tuning, the fewest parameters were tuned for these models: 9.5M and 18M for Flan-TX XL and XXL, respectively compared to 110M for BERT. The negative class generally had the best performance overall, followed by Relationship and Employment. Performance varied quite a bit across the models for the other classes.</figcaption></figure><p><span>Fig. 2. Fine-tuned LLMs versus ChatGPT-family models: </span><span>Comparison of model performance between our fine-tuned Flan-T5 models against zero- and 10-shot GPT. Macro-F1 was measured using our manually validated synthetic dataset. The GPT-turbo-0613 version of GPT3.5 and the GPT4–0613 version of GPT4 were used. Error bars indicate the 95% confidence intervals. LLM large language model.</span></p><p><span>For both tasks, the best-performing models with synthetic data augmentation used sentences from both rounds of GPT3.5 prompting. Synthetic data augmentation tended to lead to the largest performance improvements for classes with few instances in the training dataset and for which the model trained on gold-only data had very low performance (Housing, Parent, and Transportation). </span></p><p><span>The performance of the best-performing models for each task on the immunotherapy and MIMIC-III datasets are shown in </span><span>Table 4</span><span>.</span><span> Performance was similar in the immunotherapy dataset, which represents a separate but similar patient population treated at the same hospital system. We observed a performance decrement on the MIMIC-III dataset, representing a more dissimilar patient population from a different hospital system. Performance was similar between models developed with and without synthetic data.</span></p><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image51.png" title=""/><figcaption>Fig. 3. LLM bias evaluation: The proportion of synthetic sentence pairs with and without demographics injected led to a classification mismatch, meaning that the model predicted a different SDoH label for each sentence in the pair. Results are shown across race/ethnicity and gender for a any SDoH mention task and b adverse SDoH mention task. Asterisks indicate statistical significance (P ≤ 0.05) chi-squared tests for multi-class comparisons and 2-proportion z tests for binary comparisons. LLM large language model, SDoH Social determinants of health.</figcaption></figure><p><span>Ablation studies</span></p><p><span>The ablation studies showed a consistent deterioration in model performance across all SDoH tasks and categories as the volume of real gold SDoH sentences progressively decreased, although models that included synthetic data maintained performance at higher levels throughout and were less sensitive to decreases in gold data (</span><span>Figure 1, Supplementary Table 5</span><span>). When synthetic data were included in training, performance was maintained until approximately 50% of gold data were removed from the train set. Conversely, without synthetic data, performance dropped after about 10-20% of the gold data were removed from the train set mimicking a true low-resource setting. </span></p><p><span>Error analysis</span></p><p><span>The leading discrepancies between ground-truth and model prediction for each task are in </span><span>Supplementary Table 6</span><span>. Qualitative analysis revealed 4 distinct error patterns: Human annotator error; false positives and false negatives for Relationship and Support labels in the presence of any family mentions that did not correlate with the correct label; incorrect labels due to information present in the note but external to the sentence and therefore not accessible to the model or that required implied/assumed knowledge; and incorrectly labeling a non-adverse SDoH as an adverse SDoH. </span></p><p><span>ChatGPT-family model performance</span></p><p><span>When evaluating our fine-tuned Flan-T5 models on the synthetic test dataset against GPT-turbo-0613 and GPT4-0613, our model surpassed the performance of the top-performing 10-shot learning GPT model by a margin of Macro-F1 0.03 on any SDoH task (p&lt;0.01), but fall shorts on adverse SDoH task (p&lt;0.01) (</span><span>Table 5, Figure 2</span><span>).</span></p><p><span>Language model bias evaluation</span></p><p><span>Both fine-tuned Flan-T5 models and ChatGPT synthetic provided discrepant classification for sentence pairs with and without demographic information injected (</span><span>Figure 3</span><span>). However, the discrepancy rate of our fine-tuned models was nearly half that of ChatGPT: 14.3% vs. 21.5% of sentence pairs for any SDoH (P = 0.007) and 9.9% vs. 18.2% of sentence pairs for adverse SDoH (P = 0.005) for fine-tuned Flan-T5 vs. ChatGPT, respectively. ChatGPT was significantly more likely to change its classification when a female gender was injected compared to a male gender for the Any SDoH task (P = 0.01); no other within-model comparisons were statistically significant. Sentences gold-labeled as Support for both any SDoH and adverse SDoH mentions were most likely to lead to discrepant predictions for ChatGPT (56.3% (27/48)) and (21.0% (9/29)), respectively). Employment gold-labeled sentences were most-likely to lead to discrepant prediction for any SDoH mention fine-tuned model (14.4% (13/90)), and Transportation for adverse SDoH mention fine-tuned model (12.2% (6/49)). </span></p><p><span>Comparison with structured EHR data</span></p><p><span>Our best-performing models for any SDoH mention correctly identified 95.7% (89/93) patients with at least one SDoH mention, and 93.8% (45/48) patients with at least one adverse SDoH mention (</span><span>Supplemental Tables 7-8</span><span>. SDoH entered as structured Z-code in the EHR during the same timespan identified 2.0% (1/48) with at least one adverse SDoH mention (all mapped Z-codes were adverse) (</span><span>Supplementary Table 9</span><span>). </span><span>Supplementary Figures 1-2</span><span> show that patient-level performance when using model predictions out-performed Z-codes by a factor of at least 3 for every label for each task (Macro-F1 0.78 vs. 0.17 for any SDoH mention and 0.71 vs. 0.17 for adverse SDoH mention).</span></p><h2>Discussion</h2><p><span>We developed multilabel classifiers to identify the presence of 6 different SDoH documented in clinical notes, demonstrating the potential of large LMs to improve the collection of real-world data on SDoH and support appropriate allocation of resource support to patients who need it most. We identified a performance gap between a more traditional BERT classifier and larger Flan-T5 XL and XXL models. Our fine-tuned models out-performed ChatGPT-family models with zero- and few-shot learning for most SDoH classes, and were less sensitive to the injection of demographic descriptors. Compared to diagnostic codes entered as structured data, text-extracted data identified 91.8% more patients with an adverse SDoH. We also contribute new annotation guidelines as well as synthetic SDoH datasets to the research community. </span></p><p><span>All of our models performed well at identifying sentences that do not contain SDoH mentions (F1 ≥ 0.99 for all). For any SDoH mentions, performance was worst for parental status and transportation issues. For adverse SDoH mentions, performance was worst for parental status and social support. These findings are unsurprising given the marked class imbalance for all SDoH labels—Only</span><span> </span><span>3% of sentences in our training set contained any SDoH mention. Given this imbalance, our models’ ability to identify sentences that contain SDoH language is impressive. In addition, these SDoH descriptions are semantically and linguistically complex. In particular, sentences describing social support are highly variable given the variety of ways individuals can receive support from their social systems during care. Interestingly, our best-performing models demonstrated strong performance in classifying housing issues (macro-F1 0.67), which was our scarcest label with only 20 instances in the training dataset. This speaks to the potential of large LMs in improved real-world data collection for very sparsely documented information, which is the most likely to be missed via manual review.</span></p><p><span>The recent advancements in large LMs have opened a pathway for synthetic text generation that may improve model performance via data augmentation, and enable experiments that better protect patient privacy.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank">29</a></sup></span><span> This is an emerging area of research that falls within a larger body of work on synthetic patient data across a range of data types and end-uses.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/2e9c+dSIb" rel="noopener noreferrer" target="_blank">30,31</a></sup></span><span> Our study is among the first to evaluate the role of contemporary generative large LMs for synthetic clinical text to help unlock the value of unstructured data within the EHR. We were particularly interested in synthetic clinical data as a means to address the aforementioned scarcity of SDoH documentation, and our findings may provide generalizable insights for the common clinical NLP challenges of class imbalance—Many clinically important data are difficult to identify among the huge amounts of text in a patient’s EHR. We found variable benefits of synthetic data augmentation across model architecture and size; the strategy was most beneficial for the smaller Flan-T5 models and for the rarest classes where performance was dismal using gold data alone. Importantly, the ablation studies demonstrated that only approximately half of the gold-labeled dataset was needed to maintain performance when synthetic data was included in training, although synthetic data alone did not produce high-quality models. Of note, we aimed to understand whether synthetic data for augmentation could be automatically generated using ChatGPT-family models without additional human annotation, and so it is possible that manual gold-labeling could further enhance the value of these data. However, this would decrease the value of synthetic data in terms of reducing annotation effort. </span></p><p><span>Our novel approach to generating synthetic clinical sentences also enabled us to explore the potential for ChatGPT-family models, GPT3.5 and GPT4, for supporting the collection of SDoH information from the EHR. We found that fine-tuning LMs that are orders of magnitude smaller than ChatGPT-family models, even with our relatively small dataset, generally outperformed zero-shot and few-shot learning with ChatGPT-family models, consistent with prior work evaluating large LMs for clinical uses.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/B8iK+mOrJ+sWuc" rel="noopener noreferrer" target="_blank">32–34</a></sup></span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/B8iK+mOrJ" rel="noopener noreferrer" target="_blank">32,33</a></sup></span><span> Nevertheless, these models showed promising performance given that they were not explicitly trained for clinical tasks, with the caveat that it is hard to make definite conclusions based on synthetic data. Additional prompt engineering could improve the performance of ChatGPT-family models, such as developing prompts that provide details of the annotation guidelines as done by Ramachandran et al (2023).</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/sWuc" rel="noopener noreferrer" target="_blank">34</a></sup></span><span> This is an area for future study, especially once these models can be readily used with real clinical data. With additional prompt engineering and model refinement, performance of these models could improve in the future and provide a promising avenue to extract SDoH while reducing human effort needed to label training datasets.</span></p><p><span>It is well-documented that LMs learn the biases, prejudices, and racism present in the language they are trained on.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/erUz+nFAs+OckR+kgzx" rel="noopener noreferrer" target="_blank">35–38</a></sup></span><span> Thus, it is essential to evaluate how LMs could propagate existing biases, which in clinical settings could amplify the health disparities crisis.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/j1dN+8yTi+Zp8L" rel="noopener noreferrer" target="_blank">1–3</a></sup></span><span> We were especially concerned that SDoH-containing language may be especially prone to eliciting these biases. Both our fine-tuned models and ChatGPT altered their SDoH classification predictions when demographics and gender descriptors were injected into sentences, although the fine-tuned models were significantly more robust than ChatGPT. Although not significantly different, it is worth noting that for both the fine-tuned models and ChatGPT, Hispanic and Black descriptors were most likely to change the classification for any SDoH and adverse SDoH mentions, respectively. This lack of significance may be due to the small numbers in this evaluation, and future work is critically needed to further evaluate bias in clinical LMs. We have made our paired demographic-injected sentences openly available for future efforts on LM bias evaluation.</span></p><p><span>SDoH are notoriously under-documented in existing EHR structured data.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/NfPNB+HNP8d+xuWCW+24iW" rel="noopener noreferrer" target="_blank">10–12,39</a></sup></span><span> Our findings that text-extracted SDoH information was better able to identify patients with adverse SDoH than relevant billing codes are in agreement with prior work showing under-utilization of Z-codes</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/NfPNB+HNP8d" rel="noopener noreferrer" target="_blank">10,11</a></sup></span><span>. Most EMR systems have other ways to enter SDoH information as structured data which may have more complete documentation, however these did not exist for most of our target SDoH. Lyberger et al. evaluated other EHR sources of structured SDoH data, and similarly found that NLP methods are a complementary source SDoH information extraction, and were able to identify 10-30% of patients with tobacco, alcohol, and homelessness risk factors documented only in unstructured text</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/XEymp" rel="noopener noreferrer" target="_blank">22</a></sup></span><span>. </span></p><p><span>There have been several prior studies developing NLP methods to extract SDoH from the EHR.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/dwSP+QKOo+3Z4R+tPmm+EfrS+v7vl+C5qx+ywEU+1P2G+cN0M" rel="noopener noreferrer" target="_blank">13–21,40</a></sup></span><span> The most common SDoH targeted in prior efforts include smoking history, substance use, alcohol use, and homelessness.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank">23</a></sup></span><span> In addition, many prior efforts focus only on text in the Social History section of notes. In a recent shared task on alcohol, drug, tobacco, employment, and living situation event extraction from Social History sections, pre-trained LMs similarly provided best performance.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/fCVG" rel="noopener noreferrer" target="_blank">41</a></sup></span><span> Using this dataset, one study found that sequence-to-sequence approaches out-performed classification approaches, in line with our findings.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/CpfF" rel="noopener noreferrer" target="_blank">42</a></sup></span><span> In addition to our technical innovations, our work adds to prior efforts by investigating SDoH that are less commonly targeted for extraction but nonetheless have been shown to impact healthcare.</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/uwVf+iwLA+YnfS+cq7p+eLSX+NszP+qacn+izwc+BTQg" rel="noopener noreferrer" target="_blank">43–51</a></sup></span><span> We also developed methods that can mine information from full clinic notes, not only Social History sections—a fundamentally more challenging task with a much larger class imbalance. Clinically-impactful SDoH information is often scattered throughout other note sections and many note types, such as many inpatient progress notes and notes written by nurses and social workers, do not consistently contain Social History sections. </span></p><p><span>Our study has limitations. First, our training and out-of-domain datasets come from a predominantly white population treated at hospitals in Boston, Massachusetts in the United States of America. This limits the generalizability of our findings. We could not exhaustively assess the many methods to generate synthetic data from ChatGPT. Instead, we chose to investigate prompting methods that could be easily reproduced by others and did not require extensive task-specific optimization, as this is likely not feasible for the many clinical NLP tasks that one may wish to generate synthetic data on. Incorporating real clinical examples in the prompt would likely improve the quality of the synthetic data, and is an area of future research when large generative LMs become more widely available for use with protected health information and within the resource constraints of academic researchers and healthcare systems. Because we could not evaluate ChatGPT-family models using protected health information, our evaluations are limited to manually-verified synthetic sentences. Thus, our reported performance may not completely reflect true performance on real clinical text. Because the synthetic sentences were generated using ChatGPT itself, and ChatGPT presumably has not been trained on clinical text, we hypothesize that if anything, performance would be worse on real clinical data. Finally, our models can only be as good as the annotated corpus. SDoH annotation is challenging due to its conceptually complex nature, especially for the Support tag, and labeling may also be subject to annotator bias</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/vnxY" rel="noopener noreferrer" target="_blank">52</a></sup></span><span>, all of which may impact ultimate performance. </span></p><p><span>Our findings highlight the potential of large LMs to improve real-world data collection and identification of SDoH from the EHR. In addition, synthetic clinical text generated by large LMs may enable better identification of rare events documented in the EHR, although more work is needed to optimize generation methods. Our fine-tuned models were less prone to bias than ChatGPT-family models and out-performed for most SDoH classes, especially any SDoH mentions, despite being orders of magnitude smaller. In the future, these models could improve our understanding of drivers of health disparities by improving real-world evidence, and could directly support patient care by flagging patients who may benefit most from proactive resource and social work referral.</span></p><h2>Methods</h2><p><span>Data</span></p><p><span>Table 1 describes the patient populations of the datasets used in this study. Gender and race/ethnicity data and descriptors were collected from the EHR. These are generally collected either directly from the patient at registration, or by a provider, but the mode of collection for each data point was not available. Our primary dataset consisted of a corpus of 800 clinic notes from 770 patients with cancer who received radiotherapy (RT) at the Department of Radiation Oncology at Brigham and Women’s Hospital/Dana-Farber Cancer Institute in Boston, Massachusetts from 2015-2022. We also created two out-of-domain test datasets. First, we collected 200 clinic notes from 170 patients with cancer treated with immunotherapy at Dana-Farber Cancer, and not present in the RT dataset. Second, we collected 200 notes from 183 patients in the MIMIC (Medical Information Mart for Intensive Care)-III database</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/43rQc+l1GSM" rel="noopener noreferrer" target="_blank">53,54</a></sup></span><span>, which includes data associated with patients admitted to the critical care units at Beth Israel Deaconess Medical Center in Boston, Massachusetts from 2001-2008. This study was approved by the Mass General Brigham institutional review board, and consent was waived as this was deemed exempt human subjects research.</span></p><p><span>Only notes written by physicians, physician assistants, nurse practitioners, registered nurses, and social workers were included. To maintain a minimum threshold of information, we excluded notes with fewer than 150 tokens across all provider types. This helped ensure that the selected notes contained sufficient textual content. For notes written by all providers save social workers, we excluded notes containing any section longer than 500 tokens to avoid excessively lengthy sections that might have included less relevant or redundant information. For physician, physician assistant, and nurse practitioner notes, we used a customized medSpacy</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/nDjDz+W72ul" rel="noopener noreferrer" target="_blank">55,56</a></sup></span><span> sectionizer to include only notes that contained at least one of the following sections: Assessment and Plan, Social History, and History/Subjective. </span></p><p><span>In addition, for the RT dataset, we established a date range, considering notes within a window of 30 days before the first treatment and 90 days after the last treatment. Additionally, in the fifth round of annotation, we specifically excluded notes from patients with zero social work notes. This decision ensured that we focused on individuals who had received social work intervention or had pertinent social context documented in their notes. For the immunotherapy dataset, we ensured that there was no patient overlap between RT and immunotherapy notes. We also specifically selected notes from patients with at least one social work note. To further refine the selection, we considered notes with a note date one month before or after the patient's first social work note or after it. For the MIMIC-III dataset, only notes written by physicians, social workers, and nurses were included for analysis. We focused on patients who had at least one social work note, without any specific date range criteria. </span></p><p><span>Prior to annotation, all notes were segmented into sentences using the syntok</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/Gjq4k" rel="noopener noreferrer" target="_blank">57</a></sup></span><span> sentence segmenter as well as split on bullet points “•”. This method was used for all notes in the radiotherapy, immunotherapy, and MIMIC datasets for sentence-level annotation and subsequent classification.</span></p><p><span>Task definition and data labeling</span></p><p><span>We defined our label schema and classification tasks by first carrying out interviews with subject matter experts, including social workers, resource specialists, and oncologists, to determine SDoH that are clinically relevant but not already readily available as structured data in the EHR, especially as dynamic features over time. After initial interviews, a set of exploratory pilot annotations was conducted on a subset of clinical notes and preliminary annotation guidelines were developed. The guidelines were then iteratively refined and finalized based on the pilot annotations and additional input from subject matter experts. The following SDoH categories and their attributes were selected for inclusion in the project: Employment status (employed, unemployed, underemployed, retired, disability, student), Housing issue (financial status, undomiciled, other), Transportation issue (distance, resource, other), Parental status (if the patient has a child under 18 years old), Relationship (married, partnered, widowed, divorced, single), and Social support (presence or absence of social support). </span></p><p><span>We defined two multilabel sentence-level classification tasks:</span></p><ol start="1"><li><span>Any SDoH mentions: The presence of language describing an SDoH category as defined above, regardless of the attribute.</span></li><li><span>Adverse SDoH mentions: The presence or absence of language describing an SDoH category with an attribute that could create an additional social work or resource support need for patients:</span></li></ol><ul><li><span>Employment status</span><span>: </span><span>unemployed, underemployed, disability</span></li><li><span>Housing issue</span><span>: </span><span>financial status, undomiciled, other</span></li><li><span>Transportation issue</span><span>: </span><span>distance, resources, other</span></li><li><span>Parental status</span><span>: </span><span>having a child under 18 years old </span></li><li><span>Relationship</span><span>: </span><span>widowed, divorced, single</span></li><li><span>Social support</span><span>: </span><span>absence of social support</span></li></ul><p><span>After finalizing the annotation guidelines, two annotators manually annotated the RT corpus. In total, ten thousand one-hundred clinical notes were annotated line-by-line using the annotation software Multi-document Annotation Environment (MAE v2.2.13).</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/P9XW" rel="noopener noreferrer" target="_blank">58</a></sup></span><span> A total of 300/800 (37.5%) of the notes underwent dual annotation by two data scientists across 4 rounds. After each round, the data scientists and an oncologist performed discussion-based adjudication. Before adjudication, dually-annotated notes had a Krippendorf’s alpha agreement of 0.86 and Cohen’s Kappa of 0.86 for any SDoH mention categories. For adverse SDoH mentions, notes had a Krippendorf’s alpha agreement of 0.76 and Cohen’s Kappa of 0.76. Detailed agreement metrics are in </span><span>Supplementary Tables 1-2</span><span>. A single annotator then annotated the remaining radiotherapy notes, the immunotherapy dataset, and the MIMIC-III dataset. </span><span>Table 2</span><span> describes the distribution of labels across the datasets </span></p><p><span>The annotation/adjudication team was composed of one board-certified radiation oncologist who completed a postdoctoral fellowship in clinical natural language processing, a Master’s-level computational linguist with a Bachelor’s degree in linguistics and one year prior experience working specifically with clinical text, and a Master’s student in computational linguistics with a Bachelor’s degree in linguistics. The radiation oncologist and Master’s level computational linguist led the development of the annotation guidelines, and trained the Master’s student in SDoH annotation over a period of 1 month via review of the annotation guidelines and iterative review of pilot annotations. During adjudication, if there was still ambiguity, we discussed with the two Resource Specialists on the research team to provide input in adjudication. </span></p><p><span>Data augmentation</span></p><p><span>We employed synthetic data generation methods to assess the impact of data augmentation for the positive class, and also to enable an exploratory evaluation of proprietary large LMs that could not be downloaded locally thus cannot be used with protected health information. In round 1, GPT-turbo-0301(ChatGPT) version of GPT3.5 via the OpenAI</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/aC6KA" rel="noopener noreferrer" target="_blank">59</a></sup></span><span> API was prompted to generate new sentences for each SDoH category, using sentences from the annotation guidelines as references. In round 2, in order to generate more linguistic diversity, the sample synthetic sentences output from round 1 were taken as references to again generate another set of synthetic sentences. One hundred sentences per category were generated in each round. </span><span>Supplementary Table 3</span><span> shows the prompts for each sentence label type.</span></p><p><span>Synthetic test set generation </span></p><p><span>Iteration 1 for generating SDoH sentences involved prompting the 538 synthetic sentences to be manually validated to evaluate ChatGPT, which cannot be used with protected health information. Of these, after human review only 480 were found to have any SDoH mention, and 289 to have an adverse SDoH mention (Table</span><span> </span><span>2). For all synthetic data generation methods, no real patient data were used in prompt development or fine-tuning. </span></p><p><span>Model development</span></p><p><span>The radiotherapy corpus was split into a 60%/20%/20% distribution for training, development, and testing respectively. The entire immunotherapy and MIMIC-III corpora were held-out for out-of-domain test and were not used during model development.</span></p><p><span>The experimental phase of this study focused on investigating the effectiveness of different machine learning models and data settings for the classification of SDoH. We explored one multi-label BERT model as a baseline, namely bert-base-uncased</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/ABnp" rel="noopener noreferrer" target="_blank">60</a></sup></span><span>, as well as a range of Flan-T5 models</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/X5d6+eb93" rel="noopener noreferrer" target="_blank">61,62</a></sup></span><span> including Flan-T5 base, large, XL, and XXL; where XL and XXL used a parameter efficient tuning method (low-rank adaptation (LoRA)</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/xoIw" rel="noopener noreferrer" target="_blank">63</a></sup></span><span>). Binary cross-entropy loss with logits was used for BERT and cross-entropy loss for the Flan T5 models. Given the large class imbalance, non-SDoH sentences were undersampled during training. We assessed the impact of adding synthetic data on model performance. Details on model hyper-parameters are in </span><span>Supplementary Methods</span><span>.</span></p><p><span>For sequence-to-sequence models, input consisted of the input sentence with “summarize” appended in front, and the target label (when used during training) was the text span of the label from the target vocabulary. Because the output did not always exactly correspond to the target vocabulary, we post-processed the model output, which was a simple split function on “,” and dictionary mapping from observed miss-generation e.g., “RELAT → RELATIONSHIP”. Examples of this label resolution are in </span><span>Supplementary Methods.</span></p><p><span>Ablation studies</span></p><p><span>Ablation studies were carried out to understand the impact of manually labeled training data quantity on performance when synthetic SDoH data is included in the training dataset. First, models were trained using 10%, 25%, 40%, 50%, 70%, 75%, and 90% of manually labeled sentences; both SDOH and non-SDOH sentences were reduced at the same rate. Evaluation was on the RT test set. </span></p><p><span>Evaluation</span></p><p><span>During training and fine-tuning, we evaluated all models using the RT development set and assessed their final performance using bootstrap sampling of the held-out RT test set. Bootstrap sample number and size was calculated to achieve a precision level for standard error of macro F1 of +/- 0.01. The mean and 95% confidence intervals from the bootstrap samples were calculated from the resulting bootstrap samples. We also sampled to ensure that our standard error on the 95% confidence interval limits was &lt; 0.01 as follows: Our selected bootstrap sample size matched the test data size, sampling with replacement. We then computed the 5th and 95th percentile values for each of the calculated k samples from the resulting distributions. The standard deviation of these percentile values was subsequently determined to establish the precision of the confidence interval limits. Examples of the bootstrap sampling calculations are in </span><span>Supplementary Methods</span><span>.</span></p><p><span>For each classification task, we calculated precision/positive predictive value, recall/sensitivity, and F1 (harmonic mean of recall and precision) as follows:</span></p><ul><li><span>Precision = TP/(TP+FP)</span></li><li><span>Recall = TP/(TP+FN)</span></li><li><span>F1 = (2*Precision*Recall)/(Precision+Recall)</span></li><li><span>TP = true positives, FP = false positives, FN = false negatives</span></li></ul><p><span>Manual error analysis was conducted on the radiotherapy dataset using the best-performing model.</span></p><p><span>ChatGPT-family model evaluation</span></p><p><span>To evaluate ChatGPT, the Scikit-LLM</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/yjfVx4/yYPKc" rel="noopener noreferrer" target="_blank">64</a></sup></span><span> multi-label zero-shot classifier and few-shot binary classifier were adapted to form a multi-label zero- and few-shot classifier (</span><span>Figure 2</span><span>). A subset of 480 synthetic sentences whose labels were manually validated, were used for testing. Test sentences were inserted into the following prompt template, which instructs ChatGPT to act as a multi-label classifier model, and to label the sentences accordingly:</span></p><p><span>“Sample input: [TEXT]</span></p><p><span>Sample target: [LABELS]</span><span>”</span></p><p><span>[TEXT]</span><span> wa</span><span>s the exemplar from the development/exemplar set.</span></p><p><span>[LABELS]</span><span> wa</span><span>s a comma-separated</span><span> list of the labels for that exemplar, e.g. PARENT,RELATIONSHIP.</span></p><p><span>Of note, because we were unable to generate high-quality synthetic non-SDoH sentences, these classifiers did not include a negative class. We evaluated the most current ChatGPT model freely available at the time of this work, GPT-turbo-0613, as well as GPT4-0613, via the OpenAI API with temperature 0 for reproducibility.</span></p><p><span>Language model bias evaluation</span></p><p><span>In order to test for bias in our best-performing models and in large LMs pre-trained on general text, we used GPT4 to insert demographic descriptors into our synthetic data, as illustrated below. GPT4 was supplied with our synthetically-generated test sentences, and prompted to insert demographic information into them. For example, a sentence starting with "Widower admits fears surrounding potential judgment…" might become “Hispanic widower admits fears surrounding potential judgment…". The prompt was as follows (in a batch of 10 ensure demographic variations):</span></p><table class="chapter-table"><tr><td colspan="1" rowspan="1"><p><span>"role": "user", "content":</span><span> “</span><span>[ORIGINAL SENTENCE]</span></p><p><span> swap the sentences patients above to one of the race/ethnicity [Asian, Black, white, Hispanic] and gender, and put the modified race and gender in bracket at the beginning like this </span></p><p><span>Owner operator food truck selling gourmet grilled cheese sandwiches around town =&gt; </span></p><p><span>[Asian female] Asian woman owner operator of a food truck selling gourmet grilled cheese sandwiches around town”</span></p><p><span>[ORIGINAL SENTENCE]was a sentence from a selected subset of our GPT-3.5-generated synthetic data </span></p></td></tr></table><p><span>These sentences were then manually validated; 419 had any SDoH mention, and 253 had an adverse SDoH mention. </span></p><p><span>Comparison with structured EHR data</span></p><p><span>To assess the completeness of SDoH documentation in structured versus unstructured EHR data, we collected Z-codes for all patients in our test set. Z-codes are SDoH-related ICD-10-CM diagnostic codes, mapped most closely with our SDoH categories present as structured data for the radiotherapy dataset (</span><span>Supplementary Table 4</span><span>). Text-extracted patient-level SDoH information was defined as the presence of one or more labels in any note. We compared these patient-level labels to structured Z-codes entered in the EHR during the same time frame.</span></p><p><span>Statistical analysis</span></p><p><span>Macro-F1 performance for each model type was compared when developed with or without synthetic data and for the ChatGPT-family model comparisons using the Mann-Whitney U-test. The rate of discrepant SDoH classifications with and without the injection of demographic information were compared between the best-performing fine-tuned models and ChatGPT using chi-squared tests for multi-class comparisons and 2-proportion z-tests for binary comparisons. A 2-sided P ≤ 0.05 was considered statistically significant. Statistical analyses were carried out using the statistical Python package in scipy (Scipy.org). Python version 3.9.16 (Python Software Foundation) was used to carry out this work.</span></p><p><span>Data availability statement: </span><span>The RT and immunotherapy datasets cannot be shared for the privacy of the individuals whose data were used in this study. All synthetic datasets used in this study are available at: https://github.com/AIM-Harvard/SDoH. The annotated MIMIC-III dataset is available after completion of a data use agreement at https://physionet.org/content/annotation-dataset-sdoh/1.0.1/.</span></p><p><span>Code availability statement:</span><span> The final annotation guidelines and all synthetic datasets used in this study are available at: </span><span><a href="https://github.com/AIM-Harvard/SDoH" rel="noopener noreferrer" target="_blank">https://github.com/AIM-Harvard/SDoH</a></span><span>.</span></p><p><span>Please view the full Tables and appendix at:</span><span> </span><span><a href="https://www.nature.com/articles/s41746-023-00970-0" rel="noopener noreferrer" target="_blank">https://www.nature.com/articles/s41746-023-00970-0</a></span></p><h2>References</h2><p><span>1. </span><span><a href="http://paperpile.com/b/yjfVx4/j1dN" rel="noopener noreferrer" target="_blank">Lavizzo-Mourey, R. J., Besser, R. E. &amp; Williams, D. R. Understanding and Mitigating Health Inequities - Past, Current, and Future Directions. </a></span><span><a href="http://paperpile.com/b/yjfVx4/j1dN" rel="noopener noreferrer" target="_blank">N. Engl. J. Med.</a></span><span><a href="http://paperpile.com/b/yjfVx4/j1dN" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/j1dN" rel="noopener noreferrer" target="_blank">384</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/j1dN" rel="noopener noreferrer" target="_blank">, 1681–1684 (2021).</a></span></p><p><span>2. </span><span><a href="http://paperpile.com/b/yjfVx4/8yTi" rel="noopener noreferrer" target="_blank">Chetty, R. </a></span><span><a href="http://paperpile.com/b/yjfVx4/8yTi" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/8yTi" rel="noopener noreferrer" target="_blank"> The Association Between Income and Life Expectancy in the United States, 2001-2014. </a></span><span><a href="http://paperpile.com/b/yjfVx4/8yTi" rel="noopener noreferrer" target="_blank">JAMA</a></span><span><a href="http://paperpile.com/b/yjfVx4/8yTi" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/8yTi" rel="noopener noreferrer" target="_blank">315</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/8yTi" rel="noopener noreferrer" target="_blank">, 1750–1766 (2016).</a></span></p><p><span>3. </span><span><a href="http://paperpile.com/b/yjfVx4/Zp8L" rel="noopener noreferrer" target="_blank">Caraballo, C. </a></span><span><a href="http://paperpile.com/b/yjfVx4/Zp8L" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/Zp8L" rel="noopener noreferrer" target="_blank"> Excess Mortality and Years of Potential Life Lost Among the Black Population in the US, 1999-2020. </a></span><span><a href="http://paperpile.com/b/yjfVx4/Zp8L" rel="noopener noreferrer" target="_blank">JAMA</a></span><span><a href="http://paperpile.com/b/yjfVx4/Zp8L" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/Zp8L" rel="noopener noreferrer" target="_blank">329</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/Zp8L" rel="noopener noreferrer" target="_blank">, 1662–1670 (2023).</a></span></p><p><span>4. </span><span><a href="http://paperpile.com/b/yjfVx4/9pBzf" rel="noopener noreferrer" target="_blank">Social determinants of health. </a></span><span><a href="http://www.who.int/social_determinants/sdh_definition/en/" rel="noopener noreferrer" target="_blank">http://www.who.int/social_determinants/sdh_definition/en/</a></span><span><a href="http://paperpile.com/b/yjfVx4/9pBzf" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>5. </span><span><a href="http://paperpile.com/b/yjfVx4/HoSYw" rel="noopener noreferrer" target="_blank">Franke, H. A. Toxic Stress: Effects, Prevention and Treatment. </a></span><span><a href="http://paperpile.com/b/yjfVx4/HoSYw" rel="noopener noreferrer" target="_blank">Children</a></span><span><a href="http://paperpile.com/b/yjfVx4/HoSYw" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/HoSYw" rel="noopener noreferrer" target="_blank">1</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/HoSYw" rel="noopener noreferrer" target="_blank">, 390–402 (2014).</a></span></p><p><span>6. </span><span><a href="http://paperpile.com/b/yjfVx4/VXeKa" rel="noopener noreferrer" target="_blank">Nelson, C. A. </a></span><span><a href="http://paperpile.com/b/yjfVx4/VXeKa" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/VXeKa" rel="noopener noreferrer" target="_blank"> Adversity in childhood is linked to mental and physical health throughout life. </a></span><span><a href="http://paperpile.com/b/yjfVx4/VXeKa" rel="noopener noreferrer" target="_blank">BMJ</a></span><span><a href="http://paperpile.com/b/yjfVx4/VXeKa" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/VXeKa" rel="noopener noreferrer" target="_blank">371</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/VXeKa" rel="noopener noreferrer" target="_blank">, m3048 (2020).</a></span></p><p><span>7. </span><span><a href="http://paperpile.com/b/yjfVx4/dQla1" rel="noopener noreferrer" target="_blank">Shonkoff, J. P., Garner, A. S., Committee on Psychosocial Aspects of Child and Family Health, Committee on Early Childhood, Adoption, and Dependent Care &amp; Section on Developmental and Behavioral Pediatrics. The lifelong effects of early childhood adversity and toxic stress. </a></span><span><a href="http://paperpile.com/b/yjfVx4/dQla1" rel="noopener noreferrer" target="_blank">Pediatrics</a></span><span><a href="http://paperpile.com/b/yjfVx4/dQla1" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/dQla1" rel="noopener noreferrer" target="_blank">129</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/dQla1" rel="noopener noreferrer" target="_blank">, e232–46 (2012).</a></span></p><p><span>8. </span><span><a href="http://paperpile.com/b/yjfVx4/zvwv7" rel="noopener noreferrer" target="_blank">Turner-Cobb, J. M., Sephton, S. E., Koopman, C., Blake-Mortimer, J. &amp; Spiegel, D. Social support and salivary cortisol in women with metastatic breast cancer. </a></span><span><a href="http://paperpile.com/b/yjfVx4/zvwv7" rel="noopener noreferrer" target="_blank">Psychosom. Med.</a></span><span><a href="http://paperpile.com/b/yjfVx4/zvwv7" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/zvwv7" rel="noopener noreferrer" target="_blank">62</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/zvwv7" rel="noopener noreferrer" target="_blank">, 337–345 (2000).</a></span></p><p><span>9. </span><span><a href="http://paperpile.com/b/yjfVx4/QlpcC" rel="noopener noreferrer" target="_blank">Hood, C. M., Gennuso, K. P., Swain, G. R. &amp; Catlin, B. B. County Health Rankings: Relationships Between Determinant Factors and Health Outcomes. </a></span><span><a href="http://paperpile.com/b/yjfVx4/QlpcC" rel="noopener noreferrer" target="_blank">Am. J. Prev. Med.</a></span><span><a href="http://paperpile.com/b/yjfVx4/QlpcC" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/QlpcC" rel="noopener noreferrer" target="_blank">50</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/QlpcC" rel="noopener noreferrer" target="_blank">, 129–135 (2016).</a></span></p><p><span>10. </span><span><a href="http://paperpile.com/b/yjfVx4/NfPNB" rel="noopener noreferrer" target="_blank">Truong, H. P. </a></span><span><a href="http://paperpile.com/b/yjfVx4/NfPNB" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/NfPNB" rel="noopener noreferrer" target="_blank"> Utilization of Social Determinants of Health ICD-10 Z-Codes Among Hospitalized Patients in the United States, 2016-2017. </a></span><span><a href="http://paperpile.com/b/yjfVx4/NfPNB" rel="noopener noreferrer" target="_blank">Med. Care</a></span><span><a href="http://paperpile.com/b/yjfVx4/NfPNB" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/NfPNB" rel="noopener noreferrer" target="_blank">58</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/NfPNB" rel="noopener noreferrer" target="_blank">, 1037–1043 (2020).</a></span></p><p><span>11. </span><span><a href="http://paperpile.com/b/yjfVx4/HNP8d" rel="noopener noreferrer" target="_blank">Heidari, E., Zalmai, R., Richards, K., Sakthisivabalan, L. &amp; Brown, C. Z-code documentation to identify social determinants of health among Medicaid beneficiaries. </a></span><span><a href="http://paperpile.com/b/yjfVx4/HNP8d" rel="noopener noreferrer" target="_blank">Res. Social Adm. Pharm.</a></span><span><a href="http://paperpile.com/b/yjfVx4/HNP8d" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/HNP8d" rel="noopener noreferrer" target="_blank">19</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/HNP8d" rel="noopener noreferrer" target="_blank">, 180–183 (2023).</a></span></p><p><span>12. </span><span><a href="http://paperpile.com/b/yjfVx4/xuWCW" rel="noopener noreferrer" target="_blank">Wang, M., Pantell, M. S., Gottlieb, L. M. &amp; Adler-Milstein, J. Documentation and review of social determinants of health data in the EHR: measures and associated insights. </a></span><span><a href="http://paperpile.com/b/yjfVx4/xuWCW" rel="noopener noreferrer" target="_blank">J. Am. Med. Inform. Assoc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/xuWCW" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/xuWCW" rel="noopener noreferrer" target="_blank">28</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/xuWCW" rel="noopener noreferrer" target="_blank">, 2608–2616 (2021).</a></span></p><p><span>13. </span><span><a href="http://paperpile.com/b/yjfVx4/dwSP" rel="noopener noreferrer" target="_blank">Conway, M. </a></span><span><a href="http://paperpile.com/b/yjfVx4/dwSP" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/dwSP" rel="noopener noreferrer" target="_blank"> Moonstone: a novel natural language processing system for inferring social risk from clinical narratives. </a></span><span><a href="http://paperpile.com/b/yjfVx4/dwSP" rel="noopener noreferrer" target="_blank">J. Biomed. Semantics</a></span><span><a href="http://paperpile.com/b/yjfVx4/dwSP" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/dwSP" rel="noopener noreferrer" target="_blank">10</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/dwSP" rel="noopener noreferrer" target="_blank">, 1–10 (2019).</a></span></p><p><span>14. </span><span><a href="http://paperpile.com/b/yjfVx4/QKOo" rel="noopener noreferrer" target="_blank">Bejan, C. A. </a></span><span><a href="http://paperpile.com/b/yjfVx4/QKOo" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/QKOo" rel="noopener noreferrer" target="_blank"> Mining 100 million notes to find homelessness and adverse childhood experiences: 2 case studies of rare and severe social determinants of health in electronic health records. </a></span><span><a href="http://paperpile.com/b/yjfVx4/QKOo" rel="noopener noreferrer" target="_blank">J. Am. Med. Inform. Assoc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/QKOo" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/QKOo" rel="noopener noreferrer" target="_blank">25</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/QKOo" rel="noopener noreferrer" target="_blank">, 61–71 (2017).</a></span></p><p><span>15. </span><span><a href="http://paperpile.com/b/yjfVx4/3Z4R" rel="noopener noreferrer" target="_blank">Topaz, M., Murga, L., Bar-Bachar, O., Cato, K. &amp; Collins, S. Extracting Alcohol and Substance Abuse Status from Clinical Notes: The Added Value of Nursing Data. </a></span><span><a href="http://paperpile.com/b/yjfVx4/3Z4R" rel="noopener noreferrer" target="_blank">Stud. Health Technol. Inform.</a></span><span><a href="http://paperpile.com/b/yjfVx4/3Z4R" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/3Z4R" rel="noopener noreferrer" target="_blank">264</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/3Z4R" rel="noopener noreferrer" target="_blank">, 1056–1060 (2019).</a></span></p><p><span>16. </span><span><a href="http://paperpile.com/b/yjfVx4/tPmm" rel="noopener noreferrer" target="_blank">Gundlapalli, A. V. </a></span><span><a href="http://paperpile.com/b/yjfVx4/tPmm" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/tPmm" rel="noopener noreferrer" target="_blank"> Using natural language processing on the free text of clinical documents to screen for evidence of homelessness among US veterans. </a></span><span><a href="http://paperpile.com/b/yjfVx4/tPmm" rel="noopener noreferrer" target="_blank">AMIA Annu. Symp. Proc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/tPmm" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/tPmm" rel="noopener noreferrer" target="_blank">2013</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/tPmm" rel="noopener noreferrer" target="_blank">, 537–546 (2013).</a></span></p><p><span>17. </span><span><a href="http://paperpile.com/b/yjfVx4/EfrS" rel="noopener noreferrer" target="_blank">Hammond, K. W., Ben-Ari, A. Y., Laundry, R. J., Boyko, E. J. &amp; Samore, M. H. The Feasibility of Using Large-Scale Text Mining to Detect Adverse Childhood Experiences in a VA-Treated Population. </a></span><span><a href="http://paperpile.com/b/yjfVx4/EfrS" rel="noopener noreferrer" target="_blank">J. Trauma. Stress</a></span><span><a href="http://paperpile.com/b/yjfVx4/EfrS" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/EfrS" rel="noopener noreferrer" target="_blank">28</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/EfrS" rel="noopener noreferrer" target="_blank">, 505–514 (2015).</a></span></p><p><span>18. </span><span><a href="http://paperpile.com/b/yjfVx4/v7vl" rel="noopener noreferrer" target="_blank">Han, S. </a></span><span><a href="http://paperpile.com/b/yjfVx4/v7vl" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/v7vl" rel="noopener noreferrer" target="_blank"> Classifying social determinants of health from unstructured electronic health records using deep learning-based natural language processing. </a></span><span><a href="http://paperpile.com/b/yjfVx4/v7vl" rel="noopener noreferrer" target="_blank">J. Biomed. Inform.</a></span><span><a href="http://paperpile.com/b/yjfVx4/v7vl" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/v7vl" rel="noopener noreferrer" target="_blank">127</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/v7vl" rel="noopener noreferrer" target="_blank">, 103984 (2022).</a></span></p><p><span>19. </span><span><a href="http://paperpile.com/b/yjfVx4/C5qx" rel="noopener noreferrer" target="_blank">Rouillard, C. J., Nasser, M. A., Hu, H. &amp; Roblin, D. W. Evaluation of a Natural Language Processing Approach to Identify Social Determinants of Health in Electronic Health Records in a Diverse Community Cohort. </a></span><span><a href="http://paperpile.com/b/yjfVx4/C5qx" rel="noopener noreferrer" target="_blank">Med. Care</a></span><span><a href="http://paperpile.com/b/yjfVx4/C5qx" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/C5qx" rel="noopener noreferrer" target="_blank">60</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/C5qx" rel="noopener noreferrer" target="_blank">, 248–255 (2022).</a></span></p><p><span>20. </span><span><a href="http://paperpile.com/b/yjfVx4/ywEU" rel="noopener noreferrer" target="_blank">Feller, D. J. </a></span><span><a href="http://paperpile.com/b/yjfVx4/ywEU" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/ywEU" rel="noopener noreferrer" target="_blank"> Detecting Social and Behavioral Determinants of Health with Structured and Free-Text Clinical Data. </a></span><span><a href="http://paperpile.com/b/yjfVx4/ywEU" rel="noopener noreferrer" target="_blank">Appl. Clin. Inform.</a></span><span><a href="http://paperpile.com/b/yjfVx4/ywEU" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/ywEU" rel="noopener noreferrer" target="_blank">11</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/ywEU" rel="noopener noreferrer" target="_blank">, 172–181 (2020).</a></span></p><p><span>21. </span><span><a href="http://paperpile.com/b/yjfVx4/1P2G" rel="noopener noreferrer" target="_blank">Yu, Z. </a></span><span><a href="http://paperpile.com/b/yjfVx4/1P2G" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/1P2G" rel="noopener noreferrer" target="_blank"> A Study of Social and Behavioral Determinants of Health in Lung Cancer Patients Using Transformers-based Natural Language Processing Models. </a></span><span><a href="http://paperpile.com/b/yjfVx4/1P2G" rel="noopener noreferrer" target="_blank">AMIA Annu. Symp. Proc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/1P2G" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/1P2G" rel="noopener noreferrer" target="_blank">2021</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/1P2G" rel="noopener noreferrer" target="_blank">, 1225–1233 (2021).</a></span></p><p><span>22. </span><span><a href="http://paperpile.com/b/yjfVx4/XEymp" rel="noopener noreferrer" target="_blank">Lybarger, K. </a></span><span><a href="http://paperpile.com/b/yjfVx4/XEymp" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/XEymp" rel="noopener noreferrer" target="_blank"> Leveraging natural language processing to augment structured social determinants of health data in the electronic health record. </a></span><span><a href="http://paperpile.com/b/yjfVx4/XEymp" rel="noopener noreferrer" target="_blank">J. Am. Med. Inform. Assoc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/XEymp" rel="noopener noreferrer" target="_blank"> (2023) doi:</a></span><span><a href="http://dx.doi.org/10.1093/jamia/ocad073" rel="noopener noreferrer" target="_blank">10.1093/jamia/ocad073</a></span><span><a href="http://paperpile.com/b/yjfVx4/XEymp" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>23. </span><span><a href="http://paperpile.com/b/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank">Patra, B. G. </a></span><span><a href="http://paperpile.com/b/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank"> Extracting social determinants of health from electronic health records using natural language processing: a systematic review. </a></span><span><a href="http://paperpile.com/b/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank">J. Am. Med. Inform. Assoc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank">28</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/M3kyq" rel="noopener noreferrer" target="_blank">, 2716–2727 (2021).</a></span></p><p><span>24. </span><span><a href="http://paperpile.com/b/yjfVx4/OqrO" rel="noopener noreferrer" target="_blank">Xu, D., Chen, S. &amp; Miller, T. BCH-NLP at BioCreative VII Track 3: medications detection in tweets using transformer networks and multi-task learning. Preprint at </a></span><span>https://arxiv.org/abs/2111.13726</span><span><a href="http://paperpile.com/b/yjfVx4/OqrO" rel="noopener noreferrer" target="_blank"> (2021).</a></span></p><p><span>25. </span><span><a href="http://paperpile.com/b/yjfVx4/59gr" rel="noopener noreferrer" target="_blank">Chen, S. </a></span><span><a href="http://paperpile.com/b/yjfVx4/59gr" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/59gr" rel="noopener noreferrer" target="_blank"> Natural Language Processing to Automatically Extract the Presence and Severity of Esophagitis in Notes of Patients Undergoing Radiotherapy. </a></span><span><a href="http://paperpile.com/b/yjfVx4/59gr" rel="noopener noreferrer" target="_blank">JCO Clin Cancer Inform</a></span><span><a href="http://paperpile.com/b/yjfVx4/59gr" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/59gr" rel="noopener noreferrer" target="_blank">7</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/59gr" rel="noopener noreferrer" target="_blank">, e2300048 (2023).</a></span></p><p><span>26. Tan, R.S.Y.C. </span><span>et al.</span><span> Inferring cancer disease response fromradiology reports using large language models with data augmentation and prompting. </span><span>J Am Med Inform Assoc</span><span> </span><span>30</span><span>(10):1657-1664 (2023). </span></p><p><span>27. </span><span><a href="http://paperpile.com/b/yjfVx4/PbaK" rel="noopener noreferrer" target="_blank">Jung, J. </a></span><span><a href="http://paperpile.com/b/yjfVx4/PbaK" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/PbaK" rel="noopener noreferrer" target="_blank"> Impossible Distillation: from Low-Quality Model to High-Quality Dataset &amp; Model for Summarization and Paraphrasing. Preprint at </a></span><span>https://arxiv.org/pdf/2305.16635.pdf (2023).</span></p><p><span>28. </span><span><a href="http://paperpile.com/b/yjfVx4/RBOwB" rel="noopener noreferrer" target="_blank">Lett, E. &amp; La Cava, W. G. Translating intersectionality to fair machine learning in health sciences. </a></span><span><a href="http://paperpile.com/b/yjfVx4/RBOwB" rel="noopener noreferrer" target="_blank">Nature Machine Intelligence</a></span><span><a href="http://paperpile.com/b/yjfVx4/RBOwB" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/RBOwB" rel="noopener noreferrer" target="_blank">5</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/RBOwB" rel="noopener noreferrer" target="_blank">, 476–479 (2023).</a></span></p><p><span>29. </span><span><a href="http://paperpile.com/b/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank">Li, J. </a></span><span><a href="http://paperpile.com/b/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank"> Are synthetic clinical notes useful for real natural language processing tasks: A case study on clinical entity recognition. </a></span><span><a href="http://paperpile.com/b/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank">J. Am. Med. Inform. Assoc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank">28</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/IXYR" rel="noopener noreferrer" target="_blank">, 2193–2201 (2021).</a></span></p><p><span>30. </span><span><a href="http://paperpile.com/b/yjfVx4/2e9c" rel="noopener noreferrer" target="_blank">Chen, R. J., Lu, M. Y., Chen, T. Y., Williamson, D. F. K. &amp; Mahmood, F. Synthetic data in machine learning for medicine and healthcare. </a></span><span><a href="http://paperpile.com/b/yjfVx4/2e9c" rel="noopener noreferrer" target="_blank">Nat Biomed Eng</a></span><span><a href="http://paperpile.com/b/yjfVx4/2e9c" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/2e9c" rel="noopener noreferrer" target="_blank">5</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/2e9c" rel="noopener noreferrer" target="_blank">, 493–497 (2021).</a></span></p><p><span>31. </span><span><a href="http://paperpile.com/b/yjfVx4/dSIb" rel="noopener noreferrer" target="_blank">Jacobs, F. </a></span><span><a href="http://paperpile.com/b/yjfVx4/dSIb" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/dSIb" rel="noopener noreferrer" target="_blank"> Opportunities and Challenges of Synthetic Data Generation in Oncology. </a></span><span><a href="http://paperpile.com/b/yjfVx4/dSIb" rel="noopener noreferrer" target="_blank">JCO Clin Cancer Inform</a></span><span><a href="http://paperpile.com/b/yjfVx4/dSIb" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/dSIb" rel="noopener noreferrer" target="_blank">7</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/dSIb" rel="noopener noreferrer" target="_blank">, e2300045 (2023).</a></span></p><p><span>32. </span><span><a href="http://paperpile.com/b/yjfVx4/B8iK" rel="noopener noreferrer" target="_blank">Chen, S. </a></span><span><a href="http://paperpile.com/b/yjfVx4/B8iK" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/B8iK" rel="noopener noreferrer" target="_blank"> Evaluation of ChatGPT Family of Models for Biomedical Reasoning and Classification. Preprint at </a></span><span>https://arxiv.org/abs/2304.02496</span><span><a href="http://paperpile.com/b/yjfVx4/B8iK" rel="noopener noreferrer" target="_blank"> (2023).</a></span></p><p><span>33. </span><span><a href="http://paperpile.com/b/yjfVx4/mOrJ" rel="noopener noreferrer" target="_blank">Lehman, E. </a></span><span><a href="http://paperpile.com/b/yjfVx4/mOrJ" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/mOrJ" rel="noopener noreferrer" target="_blank"> Do We Still Need Clinical Language Models? </a></span><span><a href="http://paperpile.com/b/yjfVx4/mOrJ" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/yjfVx4/mOrJ" rel="noopener noreferrer" target="_blank"> (2023).</a></span></p><p><span>34. </span><span><a href="http://paperpile.com/b/yjfVx4/sWuc" rel="noopener noreferrer" target="_blank">Ramachandran, G. K. </a></span><span><a href="http://paperpile.com/b/yjfVx4/sWuc" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/sWuc" rel="noopener noreferrer" target="_blank"> Prompt-based Extraction of Social Determinants of Health Using Few-shot Learning. in </a></span><span><a href="http://paperpile.com/b/yjfVx4/sWuc" rel="noopener noreferrer" target="_blank">Proceedings of the 5th Clinical Natural Language Processing Workshop</a></span><span><a href="http://paperpile.com/b/yjfVx4/sWuc" rel="noopener noreferrer" target="_blank"> 385–393 (Association for Computational Linguistics, 2023).</a></span></p><p><span>35. </span><span><a href="http://paperpile.com/b/yjfVx4/erUz" rel="noopener noreferrer" target="_blank">Feng, S., Park, C. Y., Liu, Y. &amp; Tsvetkov, Y. From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models. in </a></span><span><a href="http://paperpile.com/b/yjfVx4/erUz" rel="noopener noreferrer" target="_blank">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span><span><a href="http://paperpile.com/b/yjfVx4/erUz" rel="noopener noreferrer" target="_blank"> 11737–11762 (Association for Computational Linguistics, 2023).</a></span></p><p><span>36. </span><span><a href="http://paperpile.com/b/yjfVx4/nFAs" rel="noopener noreferrer" target="_blank">Zhao, J., Wang, T., Yatskar, M., Ordonez, V. &amp; Chang, K.-W. Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints. in </a></span><span><a href="http://paperpile.com/b/yjfVx4/nFAs" rel="noopener noreferrer" target="_blank">Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</a></span><span><a href="http://paperpile.com/b/yjfVx4/nFAs" rel="noopener noreferrer" target="_blank"> 2979–2989 (Association for Computational Linguistics, 2017).</a></span></p><p><span>37. </span><span><a href="http://paperpile.com/b/yjfVx4/OckR" rel="noopener noreferrer" target="_blank">Caliskan, A., Bryson, J. J. &amp; Narayanan, A. Semantics derived automatically from language corpora contain human-like biases. </a></span><span><a href="http://paperpile.com/b/yjfVx4/OckR" rel="noopener noreferrer" target="_blank">Science</a></span><span><a href="http://paperpile.com/b/yjfVx4/OckR" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/OckR" rel="noopener noreferrer" target="_blank">356</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/OckR" rel="noopener noreferrer" target="_blank">, 183–186 (2017).</a></span></p><p><span>38. </span><span><a href="http://paperpile.com/b/yjfVx4/kgzx" rel="noopener noreferrer" target="_blank">Davidson, T., Warmsley, D., Macy, M. &amp; Weber, I. Automated Hate Speech Detection and the Problem of Offensive Language. Preprint at https://arxiv.org/pdf/1703.04009.pdf (2017).</a></span></p><p><span>39. </span><span><a href="http://paperpile.com/b/yjfVx4/24iW" rel="noopener noreferrer" target="_blank">Kharrazi, H. </a></span><span><a href="http://paperpile.com/b/yjfVx4/24iW" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/24iW" rel="noopener noreferrer" target="_blank"> The Value of Unstructured Electronic Health Record Data in Geriatric Syndrome Case Identification. </a></span><span><a href="http://paperpile.com/b/yjfVx4/24iW" rel="noopener noreferrer" target="_blank">J. Am. Geriatr. Soc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/24iW" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/24iW" rel="noopener noreferrer" target="_blank">66</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/24iW" rel="noopener noreferrer" target="_blank">, 1499–1507 (2018).</a></span></p><p><span>40. </span><span><a href="http://paperpile.com/b/yjfVx4/cN0M" rel="noopener noreferrer" target="_blank">Derton, A. </a></span><span><a href="http://paperpile.com/b/yjfVx4/cN0M" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/cN0M" rel="noopener noreferrer" target="_blank"> Natural Language Processing Methods to Empirically Explore Social Contexts and Needs in Cancer Patient Notes. </a></span><span><a href="http://paperpile.com/b/yjfVx4/cN0M" rel="noopener noreferrer" target="_blank">JCO Clin Cancer Inform</a></span><span><a href="http://paperpile.com/b/yjfVx4/cN0M" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/cN0M" rel="noopener noreferrer" target="_blank">7</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/cN0M" rel="noopener noreferrer" target="_blank">, e2200196 (2023).</a></span></p><p><span>41. </span><span><a href="http://paperpile.com/b/yjfVx4/fCVG" rel="noopener noreferrer" target="_blank">Lybarger, K., Yetisgen, M. &amp; Uzuner, Ö. The 2022 n2c2/UW shared task on extracting social determinants of health. </a></span><span><a href="http://paperpile.com/b/yjfVx4/fCVG" rel="noopener noreferrer" target="_blank">J. Am. Med. Inform. Assoc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/fCVG" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/fCVG" rel="noopener noreferrer" target="_blank">30</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/fCVG" rel="noopener noreferrer" target="_blank">, 1367–1378 (2023).</a></span></p><p><span>42. </span><span><a href="http://paperpile.com/b/yjfVx4/CpfF" rel="noopener noreferrer" target="_blank">Romanowski, B., Ben Abacha, A. &amp; Fan, Y. Extracting social determinants of health from clinical note text with classification and sequence-to-sequence approaches. </a></span><span><a href="http://paperpile.com/b/yjfVx4/CpfF" rel="noopener noreferrer" target="_blank">J. Am. Med. Inform. Assoc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/CpfF" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/CpfF" rel="noopener noreferrer" target="_blank">30</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/CpfF" rel="noopener noreferrer" target="_blank">, 1448–1455 (2023).</a></span></p><p><span>43. </span><span><a href="http://paperpile.com/b/yjfVx4/uwVf" rel="noopener noreferrer" target="_blank">Hatef, E. </a></span><span><a href="http://paperpile.com/b/yjfVx4/uwVf" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/uwVf" rel="noopener noreferrer" target="_blank"> Assessing the Availability of Data on Social and Behavioral Determinants in Structured and Unstructured Electronic Health Records: A Retrospective Analysis of a Multilevel Health Care System. </a></span><span><a href="http://paperpile.com/b/yjfVx4/uwVf" rel="noopener noreferrer" target="_blank">JMIR Med Inform</a></span><span><a href="http://paperpile.com/b/yjfVx4/uwVf" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/uwVf" rel="noopener noreferrer" target="_blank">7</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/uwVf" rel="noopener noreferrer" target="_blank">, e13802 (2019).</a></span></p><p><span>44. </span><span><a href="http://paperpile.com/b/yjfVx4/iwLA" rel="noopener noreferrer" target="_blank">Greenwald, J. L., Cronin, P. R., Carballo, V., Danaei, G. &amp; Choy, G. A Novel Model for Predicting Rehospitalization Risk Incorporating Physical Function, Cognitive Status, and Psychosocial Support Using Natural Language Processing. </a></span><span><a href="http://paperpile.com/b/yjfVx4/iwLA" rel="noopener noreferrer" target="_blank">Med. Care</a></span><span><a href="http://paperpile.com/b/yjfVx4/iwLA" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/iwLA" rel="noopener noreferrer" target="_blank">55</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/iwLA" rel="noopener noreferrer" target="_blank">, 261–266 (2017).</a></span></p><p><span>45. </span><span><a href="http://paperpile.com/b/yjfVx4/YnfS" rel="noopener noreferrer" target="_blank">Blosnich, J. R. </a></span><span><a href="http://paperpile.com/b/yjfVx4/YnfS" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/YnfS" rel="noopener noreferrer" target="_blank"> Social Determinants and Military Veterans’ Suicide Ideation and Attempt: a Cross-sectional Analysis of Electronic Health Record Data. </a></span><span><a href="http://paperpile.com/b/yjfVx4/YnfS" rel="noopener noreferrer" target="_blank">J. Gen. Intern. Med.</a></span><span><a href="http://paperpile.com/b/yjfVx4/YnfS" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/YnfS" rel="noopener noreferrer" target="_blank">35</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/YnfS" rel="noopener noreferrer" target="_blank">, 1759–1767 (2020).</a></span></p><p><span>46. </span><span><a href="http://paperpile.com/b/yjfVx4/cq7p" rel="noopener noreferrer" target="_blank">Wray, C. M. </a></span><span><a href="http://paperpile.com/b/yjfVx4/cq7p" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/cq7p" rel="noopener noreferrer" target="_blank"> Examining the Interfacility Variation of Social Determinants of Health in the Veterans Health Administration. </a></span><span><a href="http://paperpile.com/b/yjfVx4/cq7p" rel="noopener noreferrer" target="_blank">Fed. Pract.</a></span><span><a href="http://paperpile.com/b/yjfVx4/cq7p" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/cq7p" rel="noopener noreferrer" target="_blank">38</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/cq7p" rel="noopener noreferrer" target="_blank">, 15–19 (2021).</a></span></p><p><span>47. </span><span><a href="http://paperpile.com/b/yjfVx4/eLSX" rel="noopener noreferrer" target="_blank">Wang, L. </a></span><span><a href="http://paperpile.com/b/yjfVx4/eLSX" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/eLSX" rel="noopener noreferrer" target="_blank"> Disease Trajectories and End-of-Life Care for Dementias: Latent Topic Modeling and Trend Analysis Using Clinical Notes. </a></span><span><a href="http://paperpile.com/b/yjfVx4/eLSX" rel="noopener noreferrer" target="_blank">AMIA Annu. Symp. Proc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/eLSX" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/eLSX" rel="noopener noreferrer" target="_blank">2018</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/eLSX" rel="noopener noreferrer" target="_blank">, 1056–1065 (2018).</a></span></p><p><span>48. </span><span><a href="http://paperpile.com/b/yjfVx4/NszP" rel="noopener noreferrer" target="_blank">Navathe, A. S. </a></span><span><a href="http://paperpile.com/b/yjfVx4/NszP" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/NszP" rel="noopener noreferrer" target="_blank"> Hospital Readmission and Social Risk Factors Identified from Physician Notes. </a></span><span><a href="http://paperpile.com/b/yjfVx4/NszP" rel="noopener noreferrer" target="_blank">Health Serv. Res.</a></span><span><a href="http://paperpile.com/b/yjfVx4/NszP" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/NszP" rel="noopener noreferrer" target="_blank">53</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/NszP" rel="noopener noreferrer" target="_blank">, 1110–1136 (2018).</a></span></p><p><span>49. </span><span><a href="http://paperpile.com/b/yjfVx4/qacn" rel="noopener noreferrer" target="_blank">Kroenke, C. H., Kubzansky, L. D., Schernhammer, E. S., Holmes, M. D. &amp; Kawachi, I. Social networks, social support, and survival after breast cancer diagnosis. </a></span><span><a href="http://paperpile.com/b/yjfVx4/qacn" rel="noopener noreferrer" target="_blank">J. Clin. Oncol.</a></span><span><a href="http://paperpile.com/b/yjfVx4/qacn" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/qacn" rel="noopener noreferrer" target="_blank">24</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/qacn" rel="noopener noreferrer" target="_blank">, 1105–1111 (2006).</a></span></p><p><span>50. </span><span><a href="http://paperpile.com/b/yjfVx4/izwc" rel="noopener noreferrer" target="_blank">Maunsell, E., Brisson, J. &amp; Deschênes, L. Social support and survival among women with breast cancer. </a></span><span><a href="http://paperpile.com/b/yjfVx4/izwc" rel="noopener noreferrer" target="_blank">Cancer</a></span><span><a href="http://paperpile.com/b/yjfVx4/izwc" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/izwc" rel="noopener noreferrer" target="_blank">76</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/izwc" rel="noopener noreferrer" target="_blank">, 631–637 (1995).</a></span></p><p><span>51. </span><span><a href="http://paperpile.com/b/yjfVx4/BTQg" rel="noopener noreferrer" target="_blank">Schulz, R. &amp; Beach, S. R. Caregiving as a risk factor for mortality: the Caregiver Health Effects Study. </a></span><span><a href="http://paperpile.com/b/yjfVx4/BTQg" rel="noopener noreferrer" target="_blank">JAMA</a></span><span><a href="http://paperpile.com/b/yjfVx4/BTQg" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/BTQg" rel="noopener noreferrer" target="_blank">282</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/BTQg" rel="noopener noreferrer" target="_blank">, 2215–2219 (1999).</a></span></p><p><span>52. </span><span><a href="http://paperpile.com/b/yjfVx4/vnxY" rel="noopener noreferrer" target="_blank">Hovy, D. &amp; Prabhumoye, S. Five sources of bias in natural language processing. </a></span><span><a href="http://paperpile.com/b/yjfVx4/vnxY" rel="noopener noreferrer" target="_blank">Lang. Linguist. Compass</a></span><span><a href="http://paperpile.com/b/yjfVx4/vnxY" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/vnxY" rel="noopener noreferrer" target="_blank">15</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/vnxY" rel="noopener noreferrer" target="_blank">, e12432 (2021).</a></span></p><p><span>53. </span><span><a href="http://paperpile.com/b/yjfVx4/43rQc" rel="noopener noreferrer" target="_blank">Johnson, A., Pollard, T. &amp; Mark, R. MIMIC-III clinical database. (2023) doi:</a></span><span><a href="http://dx.doi.org/10.13026/C2XW26" rel="noopener noreferrer" target="_blank">10.13026/C2XW26</a></span><span><a href="http://paperpile.com/b/yjfVx4/43rQc" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>54. </span><span><a href="http://paperpile.com/b/yjfVx4/l1GSM" rel="noopener noreferrer" target="_blank">Johnson, A. E. W. </a></span><span><a href="http://paperpile.com/b/yjfVx4/l1GSM" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/l1GSM" rel="noopener noreferrer" target="_blank"> MIMIC-III, a freely accessible critical care database. </a></span><span><a href="http://paperpile.com/b/yjfVx4/l1GSM" rel="noopener noreferrer" target="_blank">Sci Data</a></span><span><a href="http://paperpile.com/b/yjfVx4/l1GSM" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/l1GSM" rel="noopener noreferrer" target="_blank">3</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/l1GSM" rel="noopener noreferrer" target="_blank">, 160035 (2016).</a></span></p><p><span>55. </span><span><a href="http://paperpile.com/b/yjfVx4/nDjDz" rel="noopener noreferrer" target="_blank">Eyre, H. </a></span><span><a href="http://paperpile.com/b/yjfVx4/nDjDz" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/nDjDz" rel="noopener noreferrer" target="_blank"> Launching into clinical space with medspaCy: a new clinical text processing toolkit in Python. </a></span><span><a href="http://paperpile.com/b/yjfVx4/nDjDz" rel="noopener noreferrer" target="_blank">AMIA Annu. Symp. Proc.</a></span><span><a href="http://paperpile.com/b/yjfVx4/nDjDz" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/yjfVx4/nDjDz" rel="noopener noreferrer" target="_blank">2021</a></sup></span><span><a href="http://paperpile.com/b/yjfVx4/nDjDz" rel="noopener noreferrer" target="_blank">, 438–447 (2021).</a></span></p><p><span>56. </span><span><a href="http://paperpile.com/b/yjfVx4/W72ul" rel="noopener noreferrer" target="_blank">MedspaCy . spaCy universe. </a></span><span><a href="http://paperpile.com/b/yjfVx4/W72ul" rel="noopener noreferrer" target="_blank">medspaCy</a></span><span><a href="http://paperpile.com/b/yjfVx4/W72ul" rel="noopener noreferrer" target="_blank"> </a></span><span><a href="https://spacy.io/universe/project/medspacy" rel="noopener noreferrer" target="_blank">https://spacy.io/universe/project/medspacy</a></span><span><a href="http://paperpile.com/b/yjfVx4/W72ul" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>57. </span><span><a href="http://paperpile.com/b/yjfVx4/Gjq4k" rel="noopener noreferrer" target="_blank">Leitner, F. </a></span><span><a href="http://paperpile.com/b/yjfVx4/Gjq4k" rel="noopener noreferrer" target="_blank">syntok: Text tokenization and sentence segmentation (segtok v2)</a></span><span><a href="http://paperpile.com/b/yjfVx4/Gjq4k" rel="noopener noreferrer" target="_blank">. (Github).</a></span></p><p><span>58. </span><span><a href="http://paperpile.com/b/yjfVx4/P9XW" rel="noopener noreferrer" target="_blank">Multi-document annotation environment. </a></span><span><a href="http://paperpile.com/b/yjfVx4/P9XW" rel="noopener noreferrer" target="_blank">MAE</a></span><span><a href="http://paperpile.com/b/yjfVx4/P9XW" rel="noopener noreferrer" target="_blank"> </a></span><span><a href="https://keighrim.github.io/mae-annotation/" rel="noopener noreferrer" target="_blank">https://keighrim.github.io/mae-annotation/</a></span><span><a href="http://paperpile.com/b/yjfVx4/P9XW" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>59. </span><span><a href="http://paperpile.com/b/yjfVx4/aC6KA" rel="noopener noreferrer" target="_blank">OpenAI API. </a></span><span><a href="http://platform.openai.com" rel="noopener noreferrer" target="_blank">http://platform.openai.com</a></span><span><a href="http://paperpile.com/b/yjfVx4/aC6KA" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>60. </span><span><a href="http://paperpile.com/b/yjfVx4/ABnp" rel="noopener noreferrer" target="_blank">Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. in </a></span><span><a href="http://paperpile.com/b/yjfVx4/ABnp" rel="noopener noreferrer" target="_blank">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</a></span><span><a href="http://paperpile.com/b/yjfVx4/ABnp" rel="noopener noreferrer" target="_blank"> 4171–4186 (Association for Computational Linguistics, 2019).</a></span></p><p><span>61. </span><span><a href="http://paperpile.com/b/yjfVx4/X5d6" rel="noopener noreferrer" target="_blank">Chung, H. W. </a></span><span><a href="http://paperpile.com/b/yjfVx4/X5d6" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/X5d6" rel="noopener noreferrer" target="_blank"> Scaling Instruction-Finetuned Language Models. Preprint at </a></span><span>https://arxiv.org/abs/2210.11416</span><span><a href="http://paperpile.com/b/yjfVx4/X5d6" rel="noopener noreferrer" target="_blank"> (2022).</a></span></p><p><span>62. </span><span><a href="http://paperpile.com/b/yjfVx4/eb93" rel="noopener noreferrer" target="_blank">Longpre, S. </a></span><span><a href="http://paperpile.com/b/yjfVx4/eb93" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/eb93" rel="noopener noreferrer" target="_blank"> The Flan Collection: Designing Data and Methods for Effective Instruction Tuning. </a></span><span><a href="http://paperpile.com/b/yjfVx4/eb93" rel="noopener noreferrer" target="_blank">arXiv [cs.AI]</a></span><span><a href="http://paperpile.com/b/yjfVx4/eb93" rel="noopener noreferrer" target="_blank"> (2023).</a></span></p><p><span>63. </span><span><a href="http://paperpile.com/b/yjfVx4/xoIw" rel="noopener noreferrer" target="_blank">Hu, E. J. </a></span><span><a href="http://paperpile.com/b/yjfVx4/xoIw" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/yjfVx4/xoIw" rel="noopener noreferrer" target="_blank"> LoRA: Low-Rank Adaptation of Large Language Models. Preprint at https://arxiv.org/abs/2106.09685 (2021).</a></span></p><p><span>64. </span><span><a href="http://paperpile.com/b/yjfVx4/yYPKc" rel="noopener noreferrer" target="_blank">Kondrashchenko, I. </a></span><span><a href="http://paperpile.com/b/yjfVx4/yYPKc" rel="noopener noreferrer" target="_blank">scikit-llm: Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks</a></span><span><a href="http://paperpile.com/b/yjfVx4/yYPKc" rel="noopener noreferrer" target="_blank">. (Github).</a></span></p><p><span>Supplementary Methods</span></p><p><span>Annotation Details</span></p><p><span>The most common type of disagreement between annotators involved one annotator labeling a sentence with a common tag (Support, Employment, and Relationship) and the other annotator not giving that sentence any label. For Employment and Relationship tags, this was most often due to simple annotation errors that get resolved through the adjudication process without much discussion. There were some instances for Employment where the language was vague as to whether the patient was on a break from work due to their job or whether they were no longer employed, which was a source of disagreements. The Support tag was a more conceptually complex tag resulting in disagreement. For example, there were disagreements based on whether a patient reporting feeling better because they had individuals visit their house, without details of the visit, consisted of support. Although it was still among the most prevalent of annotation disagreements, we believe the support tag’s complexity was minimized through pilot annotation rounds and guideline revisions. The disagreement types with &gt;5 instances are listed below:</span></p><p><span><br/></span><span>Disagreement type Count</span></p><p><span>NO_SDOH, SUPPORT_plus 27</span></p><p><span>NO_SDOH, EMPLOYMENT_employed 16</span></p><p><span>NO_SDOH, RELATIONSHIP_married 15</span></p><p><span>NO_SDOH, PARENT 8</span></p><p><span>NO_SDOH SUPPORT_minus 6</span></p><p><span>Please view the full appendix at:</span><span> https://www.nature.com/articles/s41746-023-00970-0</span></p><hr/><p><span>Hyper-parameters for model training</span></p><p><span>During the model development, the fine-tuning process of the best-performing models follows specific hyper-parameters using two </span><span>Nvidia RTX 3090 GPUs</span><span>. A per-device training batch size of 32 is used along with a learning rate of 1e-3. The model is trained for a total of 3 epochs. Additionally, the LoRA configuration is employed with a rank 'r' of 16 and a 'lora_alpha' value of 32. This configuration targets the "q" and "v" modules in the transformer layers and incorporates a dropout rate of 0.05.</span></p><p><span> per_device_train_batch_size=32,</span></p><p><span> learning_rate=1e-3, </span></p><p><span> num_train_epochs=3,</span></p><p><span> lora_config = LoraConfig(</span></p><p><span> r=16,</span></p><p><span> lora_alpha=32,</span></p><p><span> target_modules=["q", "v"],</span></p><p><span> lora_dropout=0.05,</span></p><p><span> bias="none",</span></p><p><span> task_type=TaskType.SEQ_2_SEQ_LM</span></p><p><span> )</span></p><p><span>Label resolution examples for sequence-to-sequence models</span></p><p><span> Example 1:</span></p><p><span>Source: “summarize: This is a patient with a history of heart disease.”</span></p><p><span>Target label: ‘&lt;NO_SDOH&gt;’</span></p><p><span> Output from model: “NO_SD”</span></p><p><span> Post-processed Output: [“&lt;NO_SDOH&gt;”]</span></p><p><span> Example 2:</span></p><p><span>Source: “summarize: The patient’s wife drives him to treatment every day.”</span></p><p><span> Target label: ‘RELATIONSHIP,SUPPORT’</span></p><p><span> Output from model: “RELAT,SUPPORT”</span></p><p><span> Post-processed Output: [“RELATIONSHIP”, “SUPPORT”]</span></p><hr/><p><span>Bootstrap Sampling Calculations Example</span></p><p><span>1. Set our desired precision level for standard error (SE) for the performance metric of macro-F1 to be +/- 0.01 </span></p><p><span>2. Estimate variability by taking a small number of initial samples, e.g.:</span></p><ul><li><span>Take 100 initial bootstrap samples of size k = 10,860 (full test set size) with replacement.</span></li><li><span>Calculate the standard deviation (σ) of F1 scores across these 100 bootstraps across all model pairs between gold-only data and gold+augmented data.</span></li><li><span>Let's say σ is estimated to be 0.03.</span></li></ul><p><span>3. Use the following formula to solve for n: SE = σ/√n</span></p><ul><li><span>For example, say σ was estimated to be 0.03:</span></li></ul><ul><li><span>0.01 = 0.03/√n</span></li><li><span>n = 9 *100</span></li></ul><ul><li><span>In practice, n varied from 2 to 34 across models, therefore we picked the largest (n=3400) for all comparison pairs. </span></li></ul><p><span>4. Therefore, the recommended numbers to achieve our desired SE for macro-F1:</span></p><ul><li><span>n = 3400 (number of bootstrap samples)</span></li><li><span>k = 10,860 (size of each bootstrap sample)</span></li></ul><p><span>We calculated the mean and 95% confidence intervals from the 3400 bootstrap samples, and compared the difference in macro-F1 when adding augmented data using the Mann-Whitney U-test.</span></p><p><span>We established our metric as Macro F1, and sampled to ensure that our SE on the 95% confidence interval limits was &lt; 0.01. Our selected bootstrap sample size matched the test-data size, sampling with replacement. We then computed the 5th and 95th percentile values for each of the calculated k samples from the resulting distributions. The standard deviation of these percentile values was subsequently determined to establish the precision of the confidence interval limits. For example, utilizing this methodological approach, a 95% confidence interval, accounting for a maximum variation of 5% and 95%, was ascertained to be 0.0091 for Table 3. This was validated through the execution of bootstrapping, performed 3,400 times across three distinct samples.</span></p>