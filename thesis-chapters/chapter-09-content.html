<h1>Chapter 9</h1><p class="chapter-subtitle"><span>Language Models are Surprisingly Fragile to Drug Names in Biomedical Benchmarks</span></p><hr/><p><span>Shan Chen*</span><span>, Jack Gallifant*, Pedro Moreira, Nikolaj Munch, Mingye Gao, Jackson Pond, </span></p><p><span>Leo Anthony Celi, Hugo Aerts, Thomas Hartvigsen, Danielle Bitterman</span></p><p class="chapter-meta"><a href="https://aclanthology.org/2024.findings-emnlp.726/" rel="noopener noreferrer" target="_blank"><em>Findings of the Association for Computational Linguistics: EMNLP 2024</em></a></p><h2>Summary</h2><p><span>Background<br/></span><span>Medical knowledge is highly context-dependent and includes many semantically equivalent expressions—especially for drug names, where patients often use brand names (e.g., “Advil,” “Tylenol”) instead of generics. For large language models (LLMs) applied to biomedical tasks, this variation presents a hidden fragility.</span></p><p><span>Methods<br/></span><span>We introduce a new robustness dataset, </span><span>RABBITS</span><span>, in which brand-name and generic drug names are swapped in biomedical benchmark datasets (MedQA and MedMCQA), using physician expert annotations. We evaluate both open-source and API-based LLMs on these modified datasets to measure performance drops and investigate whether pre-training data leaks/contamination contribute to the fragility.</span></p><p><span>Findings<br/></span><span>When drug names are swapped, LLMs consistently show performance drops in the 1% – 10% range, indicating surprising sensitivity to synonymous drug-name substitutions. We further show that one possible reason is contamination of benchmark test data within widely used LLM pre-training corpora, so models may rely on memorized pairs rather than true reasoning.</span></p><p><span>Interpretation<br/></span><span>Even state-of-the-art LLMs used in biomedical NLP are </span><span>fragile</span><span> to superficial lexical changes—such as switching brand and generic drug names—undermining their reliability and robustness. Our work highlights the need for more rigorous and robust testing of datasets in biomedical AI, particularly when such systems are used in clinical research or healthcare settings.</span></p><h2>Introduction</h2><p><span>Large Language Models (LLMs) are poised to transform medicine by providing data processing and decision support capabilities</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/51Gy+e3VB" rel="noopener noreferrer" target="_blank">1,2</a></sup></span><span>. However, the medical deployment of LLMs demands high accuracy and reliability, as errors can result in severe health consequences</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/uPo4+mWz4+7nb9" rel="noopener noreferrer" target="_blank">3–5</a></sup></span><span>. A key challenge is the synonymy and context-specific nature of medical language; for instance, patients might use brand names like Advil or Tylenol instead of pharmaceutically equivalent generic terms such as ibuprofen or acetaminophen. LLMs must, therefore, be able to provide consistent and accurate advice in the face of this variability. Fluctuations could lead to risks like medical misinformation, medication errors due to incorrect medication advice, and biases toward or against proprietary products. Our study investigates the effects of substituting drug names—from brand to generic and vice versa—on LLM performance.</span></p><p><span>Building on the need for robustness in medical LLM applications, numerous efforts have developed knowledge benchmarks</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/LZ8I+ejcu+v2iZ+V1vd" rel="noopener noreferrer" target="_blank">6–9</a></sup></span><span>. Yet, these initiatives primarily tackle general language tasks and often neglect the unique challenges of medical terminology in real-world settings. There is an unmet need to overcome this research gap, as the variability in medical language implies that conventional robustness evaluations might not sufficiently cater to specialized healthcare demands.</span></p><p><span>A key reason for this gap is the lack of publicly available, expert-annotated datasets specific to the healthcare domain. To address this issue, our work leverages existing medical benchmarks and employs physician expert annotators to substitute brand names with their generic counterparts and vice versa.</span></p><p><span>Our findings reveal a surprising drop in the performance of LLMs on common medical benchmarks when the drug names are swapped from generic to brand names: </span><span>4% drop in accuracy on average</span><span>. This is concerning given that patients commonly use brand names and are less likely to spot errors, especially given existing misconceptions that brand drugs are superior to equivalent generics</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/CouF+DWJc" rel="noopener noreferrer" target="_blank">10,11</a></sup></span><span>. Furthermore, we identify a potential source for this fragility: Open pretraining datasets contain substantial amounts of benchmark test data.</span></p><p><span>Our research introduces a novel category of robustness evaluation centered on drug name interchangeability. We present </span><span>RABBITS</span><span> (</span><span>R</span><span>obust </span><span>A</span><span>ssessment of </span><span>B</span><span>iomedical </span><span>B</span><span>enchmarks </span><span>I</span><span>nvolving drug </span><span>T</span><span>erm </span><span>S</span><span>ubstitutions for Language Models) a specialized dataset and leaderboard to aid in evaluating LLM performance in healthcare. Specifically, our study combines and modifies select questions from the MedMCQA and MedQA benchmarks to:</span></p><ul><li><span>Assess model robustness in understanding clinical knowledge across drug synonyms.<br/></span></li><li><span>Detect potential dataset contamination in biomedical benchmarks.<br/></span></li><li><span>Highlight the importance of robustness to nomenclature variations in the healthcare domain.</span></li></ul><h3>Related Work</h3><p>Lexical Substitution: Lexical substitution plays a crucial role in natural language processing, especially in tasks like word sense disambiguation and synonym generation. Early work by Mcarthy 12 laid the groundwork for substitution-based methods in word sense disambiguation, paving the way for subsequent advancements in the field. Recent studies by Arefyev 13 and Zhou 14 have further explored the capabilities of neural models such as BERT, RoBERTa, and XLNet in lexical substitution, showcasing significant improvements in generating contextually appropriate synonyms. In the medical domain, works by Riedl 15 and Wen 16 have developed medical abbreviation and acronym disambiguation datasets, highlighting the unique challenges in this area. Our work, RABBITS, is the first, to our knowledge, to demonstrate the use of this direct method in stress-testing the knowledge robustness of large language models.</p><p>Dataset Contamination: Dataset contamination in training data is a well-documented issue and can affect the performance and generalizability of LLMs. Many studies have aimed to detect benchmark questions within LLM training data 17–19 . For instance, research by Recht illustrated that models trained on contaminated datasets often exhibit inflated performance metrics that do not generalize well to new, unseen data. This problem is particularly concerning for medical LLMs, where inaccurate information can harm patients 3,5 .</p><p><span>Various strategies have been employed to mitigate dataset contamination. These include removing data with high n-gram overlap with benchmark datasets</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/o7lT" rel="noopener noreferrer" target="_blank">20</a></sup></span><span> and employing embedding similarity to filter out similar data</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/VetX" rel="noopener noreferrer" target="_blank">17</a></sup></span><span>. More advanced approaches involve functional evaluations, such as generating new, unique problem instances for each evaluation</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/i7v8" rel="noopener noreferrer" target="_blank">21</a></sup></span><span>. Addressing contamination is crucial for ensuring that LLMs provide reliable outputs, especially in sensitive domains like healthcare.</span></p><h3>Evaluating Model Robustness</h3><p><span>LLMs gain broad capabilities from large-scale data ingestion, but this also introduces significant challenges</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/7Z0s" rel="noopener noreferrer" target="_blank">22</a></sup></span><span>. While larger models often perform better, these improvements are not always consistent across domains</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/UVGC" rel="noopener noreferrer" target="_blank">23</a></sup></span><span>. Moreover, recent research has questioned the actual reasoning abilities of LLMs, suggesting that their performance may be inflated by dataset contamination rather than genuine problem-solving skills</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/Z1jA" rel="noopener noreferrer" target="_blank">24</a></sup></span><span>.</span></p><p><span>Some works have looked into LLMs' robustness in terms of faithfulness and fairness under clinical settings</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/SrkJ+X0L4+RImu" rel="noopener noreferrer" target="_blank">25–27</a></sup></span><span>. Medfuzz introduced a method to test LLMs' robustness in medical question answering by revealing vulnerabilities through modified benchmark questions</span><span><sup class="citation-ref"><a class="citation-link" href="https://paperpile.com/c/coPcdt/TVaD" rel="noopener noreferrer" target="_blank">28</a></sup></span><span>. However, these studies do not specifically address the unique challenges associated with clinical drug terminology and the relationship between robustness and contamination. Hence, there is a significant gap in evaluating LLM robustness for medical applications, particularly in the context of brand and generic drug name interchangeability. This gap underscores the need for focused robustness evaluations tailored to the healthcare sector.</span></p><p><span>METHOD</span><span><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image68.png" title=""/></figure></span></p><p><span><br/> </span><span>&lt;&lt; </span><span>Figure 1.</span><span> RABBITS dataset generation workflow.</span></p><p><span>Brand-Generic Pairs</span></p><p><span>Figure 1 demonstrates the overall workflow of the study. Appendix A details the full data quality assurance and dataset curation process. To create the dataset of brand and generic drug name pairs, we used the RxNorm ontology, which links normalized drug names with many pharmaceutical vocabularies. We extracted combinations of brand and generic drug names using the "ingredient of" and "tradename of" relations, resulting in 2,271 generic drugs mapped to 6,961 brands. For each generic drug, there are often multiple associated brand names. Multiple rounds of expert annotation were performed to derive a final list of 1:1 mapped brand-generic pairs for use in the transformed datasets described below.</span></p><p>Dataset Transformation: We used regular expressions to identify and replace brand and generic drug names in the questions and answers of MedQA, MedMCQA, MMLU, PubMedQA, and USMLE. MMLU and PubMedQA had fewer than 100 instances of identified drug names in the test split and were excluded from further analysis. USMLE was excluded due to its overlap with MedQA. Thus, the two datasets included in the final RABBITS benchmark are MedQA and MedMCQA .</p><p><span>The quality of the transformed datasets were iteratively reviewed by 2 physician authors (JG, DB), removing instances where replacements introduced inaccuracies, ambiguities, and/or logical inconsistencies in context. This process is described in detail in Appendix A. For the rest of the paper, we will refer to the generic-to-brand swapped benchmark as </span><span>g2b</span><span> and the brand-to-generic swapped benchmark as </span><span>b2g</span><span>.</span></p><p><span>To prevent further data contamination, we will not release the full dataset directly. The HuggingFace leaderboard will be the best way to assess new models' robustness in terms of performance. We evaluated the models using the EleutherAI lm-evaluation harness with zero-shot setting. We forked this repository, added our transformed datasets as new tasks, and made no other modifications. For API models, we used the same prompt format as the lm-evaluation harness with the default hyperparameters.</span></p><p><span>Our evaluation focuses on comparing the performance of base models (full list in Appendix Table) across the original and transformed datasets to assess the impact of synonym substitution on accuracy. We report results for g2b due to the limited number of b2g swaps observed. By doing so, we aim to determine whether models can maintain performance despite semantically equivalent pharmaceutical terminology.</span></p><p><span>All datasets and models used in accordance with owners' licenses.</span></p><h3>Results &amp; Discussion</h3><p>Drug Swapping Results: Figure 2 presents the performance of each model on the original (no-swap) and transformed (g2b) datasets, alongside the average performance and the difference between the two. The line of robustness, with a gradient of 1, represents the ideal scenario where synonym swaps do not affect the selection of answers. The plot reveals that all open-source models from 7B and above fall below this line, indicating decreased performance when drug names are swapped. We also observe a larger drop among MedMCQA over MedQA across models. Refer to Appendix C for a detailed breakdown of individual results in Table 5 and Figure 4.</p><p><span><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image11.png" title=""/></figure></span><span><br/></span><span>Figure 2.</span><span> Average performance of models on the filtered original datasets compared to the generic-to-brand versions of MedQA and MedMCA. The dashed diagonal line represents the ideal scenario where synonym swaps do not affect model performance.</span></p><p><span>Table 5 shows that most models experience a decrease in accuracy when generic names are swapped with brand names across different datasets and model sizes. Among large open-source models, the Llama-3-70B model, despite being one of the larger and more accurate models on the original dataset (no-swap accuracy of 76.6%), decreases to 69.7% accuracy with generic-to-brand swaps. Overall, API models perform better than their open-source counterparts with higher accuracy and lower performance drop. While larger open-source series like Qwen2, Llama, and Mixtral are more accurate on original datasets, they exhibit greater sensitivity to g2b swaps. Furthermore, the performance of Medical LLMs was not robust to these swaps compared to their respective base model comparisons (Appendix E). These gaps persisted after providing brand name hints, which showed only marginal improvements in model performance (see Appendix F). This suggests limitations in true comprehension and reasoning abilities.</span></p><h3>Model Knowledge of Drug Pairs via Multi-Choice Questions</h3><p><span>We evaluate whether models are able to directly map brand-to-generic drug pairs and vice versa using multiple-choice questions for all drugs that were swapped in our final benchmark dataset. Overall, a clear "scaling law" is observed in Appendix B Figure 3, where larger models (active parameter size over 13B) consistently outperform smaller models on this task, with larger open-source and API models achieving accuracy over 97%.</span></p><h3>Generic and Brand Mentions in Benchmarks and Pre-training Datasets</h3><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image64.png" title=""/><figcaption>Table 1 shows our overall dataset swapping statistics where we observe benchmark questions overwhelmingly use generic terms. We also use Infini-gram 29 to screen the common open-sourced pre-training data, including Redpajama, C4 train, Pile train, and Dolma 1.6 for drugs identified in RxNorm, filtered for terms that overlap with common terms (Appendix A, Step 1). Generic names are more common than brand names in these pre-training datasets, as Appendix D table 6 shows.</figcaption></figure><p><span>Table 1. Dataset Statistics for RABBITS</span><span>. 'Orig.' is the total questions in the original dataset. 'RABBITS' indicates the subset of questions with validated drug mentions. 'Drugs' shows the total unique drugs in RABBITS.</span></p><h3>Contamination Source from Pre-training Dataset</h3><p><span>To investigate why we see larger performance drops in MedMCQA than MedQA, we use Infini-gram API to identify overlaps with the Dolma 1.6 dataset (3.1T tokens) using size 8 n-grams. Each question's n-grams are generated and queried through the Infini-gram API.</span></p><p><span>Dataset contamination are 99.21% and 34.13% in the MedQA and MedMCQA test datasets, respectively, as Table 2 shows. We also benchmark OLMo-1.7-7B-hf, trained only on Dolma, which shows no drop in MedQA (31.22) scores compared to a 3% drop in MedMCQA (40.90 to 37.93). This likely explains the greater drop in performance in MedMCQA rather than MedQA across models (Appendix C Figure 4).</span></p><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image8.png" title=""/></figure><p><span>&lt;&lt; Table 2.</span><span> Percentage of contamination of MedQA and MedMCQA benchmarks in Dolma dataset</span></p><h2>Conclusion</h2><p><span>We find decreased performance on common medical benchmarks when using different names for the same drug, despite LLMs' ability to match these names, and that these trends scale with LLM size. This suggests that LLM performance may be driven by memorization and not reasoning ability. RABBITS underscores the importance of dataset contamination and model robustness evaluations, particularly in the medical domain. Future research should refine strategies and explore new methods for robustness and fairness evaluation.</span></p><h2>Limitations</h2><p><span>Our evaluation is limited to biomedical datasets and focuses only on pharmaceuticals. Future work will extend this approach to other medical synonyms and the impact of these variations in the retrieval and in-context setting. Although the dataset is smaller, trained physicians have curated it multiple times, ensuring its validity and the accuracy of questions after replacement. Among the pre-training dataset contamination section, we acknowledge none of these models are trained specifically among the pile, C4, RedPajama, or Dolma. However, we use this as a reasonable proxy for estimating the internet distribution.</span></p><h2>References</h2><p><span>1. </span><span><a href="http://paperpile.com/b/coPcdt/51Gy" rel="noopener noreferrer" target="_blank">Jiang, L. Y. </a></span><span><a href="http://paperpile.com/b/coPcdt/51Gy" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/51Gy" rel="noopener noreferrer" target="_blank"> Health system-scale language models are all-purpose prediction engines. </a></span><span><a href="http://paperpile.com/b/coPcdt/51Gy" rel="noopener noreferrer" target="_blank">Nature</a></span><span><a href="http://paperpile.com/b/coPcdt/51Gy" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/51Gy" rel="noopener noreferrer" target="_blank">619</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/51Gy" rel="noopener noreferrer" target="_blank">, 357–362 (2023).</a></span></p><p><span>2. </span><span><a href="http://paperpile.com/b/coPcdt/e3VB" rel="noopener noreferrer" target="_blank">Clusmann, J. </a></span><span><a href="http://paperpile.com/b/coPcdt/e3VB" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/e3VB" rel="noopener noreferrer" target="_blank"> The future landscape of large language models in medicine. </a></span><span><a href="http://paperpile.com/b/coPcdt/e3VB" rel="noopener noreferrer" target="_blank">Commun. Med. (Lond.)</a></span><span><a href="http://paperpile.com/b/coPcdt/e3VB" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/e3VB" rel="noopener noreferrer" target="_blank">3</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/e3VB" rel="noopener noreferrer" target="_blank">, 141 (2023).</a></span></p><p><span>3. </span><span><a href="http://paperpile.com/b/coPcdt/uPo4" rel="noopener noreferrer" target="_blank">Chen, S. </a></span><span><a href="http://paperpile.com/b/coPcdt/uPo4" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/uPo4" rel="noopener noreferrer" target="_blank"> The effect of using a large language model to respond to patient messages. </a></span><span><a href="http://paperpile.com/b/coPcdt/uPo4" rel="noopener noreferrer" target="_blank">Lancet Digit. Health</a></span><span><a href="http://paperpile.com/b/coPcdt/uPo4" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/uPo4" rel="noopener noreferrer" target="_blank">6</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/uPo4" rel="noopener noreferrer" target="_blank">, e379–e381 (2024).</a></span></p><p><span>4. </span><span><a href="http://paperpile.com/b/coPcdt/mWz4" rel="noopener noreferrer" target="_blank">Goodman, K. E., Yi, P. H. &amp; Morgan, D. J. AI-generated clinical summaries require more than accuracy. </a></span><span><a href="http://paperpile.com/b/coPcdt/mWz4" rel="noopener noreferrer" target="_blank">JAMA</a></span><span><a href="http://paperpile.com/b/coPcdt/mWz4" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/mWz4" rel="noopener noreferrer" target="_blank">331</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/mWz4" rel="noopener noreferrer" target="_blank">, 637–638 (2024).</a></span></p><p><span>5. </span><span><a href="http://paperpile.com/b/coPcdt/7nb9" rel="noopener noreferrer" target="_blank">Yan, Q., He, X., Yue, X. &amp; Wang, X. E. Worse than random? An embarrassingly simple probing evaluation of large multimodal models in medical VQA. in </a></span><span><a href="http://paperpile.com/b/coPcdt/7nb9" rel="noopener noreferrer" target="_blank">Findings of the Association for Computational Linguistics: ACL 2025</a></span><span><a href="http://paperpile.com/b/coPcdt/7nb9" rel="noopener noreferrer" target="_blank"> 19188–19205 (Association for Computational Linguistics, Stroudsburg, PA, USA, 2025).</a></span></p><p><span>6. </span><span><a href="http://paperpile.com/b/coPcdt/LZ8I" rel="noopener noreferrer" target="_blank">Jin, Q., Dhingra, B., Liu, Z., Cohen, W. &amp; Lu, X. PubMedQA: A Dataset for Biomedical Research Question Answering. in </a></span><span><a href="http://paperpile.com/b/coPcdt/LZ8I" rel="noopener noreferrer" target="_blank">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</a></span><span><a href="http://paperpile.com/b/coPcdt/LZ8I" rel="noopener noreferrer" target="_blank"> (Association for Computational Linguistics, Stroudsburg, PA, USA, 2019). doi:</a></span><span><a href="http://dx.doi.org/10.18653/v1/d19-1259" rel="noopener noreferrer" target="_blank">10.18653/v1/d19-1259</a></span><span><a href="http://paperpile.com/b/coPcdt/LZ8I" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>7. </span><span><a href="http://paperpile.com/b/coPcdt/ejcu" rel="noopener noreferrer" target="_blank">Hendrycks, D. </a></span><span><a href="http://paperpile.com/b/coPcdt/ejcu" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/ejcu" rel="noopener noreferrer" target="_blank"> Measuring massive multitask language understanding. </a></span><span><a href="http://paperpile.com/b/coPcdt/ejcu" rel="noopener noreferrer" target="_blank">arXiv [cs.CY]</a></span><span><a href="http://paperpile.com/b/coPcdt/ejcu" rel="noopener noreferrer" target="_blank"> (2020).</a></span></p><p><span>8. </span><span><a href="http://paperpile.com/b/coPcdt/v2iZ" rel="noopener noreferrer" target="_blank">Jin, D. </a></span><span><a href="http://paperpile.com/b/coPcdt/v2iZ" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/v2iZ" rel="noopener noreferrer" target="_blank"> What disease does this patient have? A large-scale open domain question answering dataset from medical exams. </a></span><span><a href="http://paperpile.com/b/coPcdt/v2iZ" rel="noopener noreferrer" target="_blank">Appl. Sci. (Basel)</a></span><span><a href="http://paperpile.com/b/coPcdt/v2iZ" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/v2iZ" rel="noopener noreferrer" target="_blank">11</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/v2iZ" rel="noopener noreferrer" target="_blank">, 6421 (2021).</a></span></p><p><span>9. </span><span><a href="http://paperpile.com/b/coPcdt/V1vd" rel="noopener noreferrer" target="_blank">Liu, J. </a></span><span><a href="http://paperpile.com/b/coPcdt/V1vd" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/V1vd" rel="noopener noreferrer" target="_blank"> Benchmarking large language models on CMExam -- A comprehensive Chinese medical exam dataset. </a></span><span><a href="http://paperpile.com/b/coPcdt/V1vd" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/V1vd" rel="noopener noreferrer" target="_blank"> (2023).</a></span></p><p><span>10. </span><span><a href="http://paperpile.com/b/coPcdt/CouF" rel="noopener noreferrer" target="_blank">Colgan, S. </a></span><span><a href="http://paperpile.com/b/coPcdt/CouF" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/CouF" rel="noopener noreferrer" target="_blank"> Perceptions of generic medication in the general population, doctors and pharmacists: a systematic review. </a></span><span><a href="http://paperpile.com/b/coPcdt/CouF" rel="noopener noreferrer" target="_blank">BMJ Open</a></span><span><a href="http://paperpile.com/b/coPcdt/CouF" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/CouF" rel="noopener noreferrer" target="_blank">5</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/CouF" rel="noopener noreferrer" target="_blank">, e008915 (2015).</a></span></p><p><span>11. </span><span><a href="http://paperpile.com/b/coPcdt/DWJc" rel="noopener noreferrer" target="_blank">Sewell, K., Andreae, S., Luke, E. &amp; Safford, M. M. Perceptions of and barriers to use of generic medications in a rural African American population, Alabama, 2011. </a></span><span><a href="http://paperpile.com/b/coPcdt/DWJc" rel="noopener noreferrer" target="_blank">Prev. Chronic Dis.</a></span><span><a href="http://paperpile.com/b/coPcdt/DWJc" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/DWJc" rel="noopener noreferrer" target="_blank">9</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/DWJc" rel="noopener noreferrer" target="_blank">, E142 (2012).</a></span></p><p><span>12. </span><span><a href="http://paperpile.com/b/coPcdt/muKP" rel="noopener noreferrer" target="_blank">McCarthy, D. Lexical substitution as a task for WSD evaluation. in </a></span><span><a href="http://paperpile.com/b/coPcdt/muKP" rel="noopener noreferrer" target="_blank">Proceedings of the ACL-02 workshop on Word sense disambiguation recent successes and future directions -</a></span><span><a href="http://paperpile.com/b/coPcdt/muKP" rel="noopener noreferrer" target="_blank"> (Association for Computational Linguistics, Morristown, NJ, USA, 2002). doi:</a></span><span><a href="http://dx.doi.org/10.3115/1118675.1118691" rel="noopener noreferrer" target="_blank">10.3115/1118675.1118691</a></span><span><a href="http://paperpile.com/b/coPcdt/muKP" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>13. </span><span><a href="http://paperpile.com/b/coPcdt/k7P8" rel="noopener noreferrer" target="_blank">Arefyev, N., Sheludko, B., Podolskiy, A. &amp; Panchenko, A. Always keep your target in mind: Studying semantics and improving performance of neural lexical substitution. in </a></span><span><a href="http://paperpile.com/b/coPcdt/k7P8" rel="noopener noreferrer" target="_blank">Proceedings of the 28th International Conference on Computational Linguistics</a></span><span><a href="http://paperpile.com/b/coPcdt/k7P8" rel="noopener noreferrer" target="_blank"> (International Committee on Computational Linguistics, Stroudsburg, PA, USA, 2020). doi:</a></span><span><a href="http://dx.doi.org/10.18653/v1/2020.coling-main.107" rel="noopener noreferrer" target="_blank">10.18653/v1/2020.coling-main.107</a></span><span><a href="http://paperpile.com/b/coPcdt/k7P8" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>14. </span><span><a href="http://paperpile.com/b/coPcdt/WqC4" rel="noopener noreferrer" target="_blank">Zhou, W., Ge, T., Xu, K., Wei, F. &amp; Zhou, M. BERT-based Lexical Substitution. in </a></span><span><a href="http://paperpile.com/b/coPcdt/WqC4" rel="noopener noreferrer" target="_blank">Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</a></span><span><a href="http://paperpile.com/b/coPcdt/WqC4" rel="noopener noreferrer" target="_blank"> (eds Korhonen, A., Traum, D. &amp; Màrquez, L.) 3368–3373 (Association for Computational Linguistics, Stroudsburg, PA, USA, 2019).</a></span></p><p><span>15. </span><span><a href="http://paperpile.com/b/coPcdt/NiSK" rel="noopener noreferrer" target="_blank">Riedl, M., Glass, M. &amp; Gliozzo, A. Lexical substitution for the medical domain. in </a></span><span><a href="http://paperpile.com/b/coPcdt/NiSK" rel="noopener noreferrer" target="_blank">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</a></span><span><a href="http://paperpile.com/b/coPcdt/NiSK" rel="noopener noreferrer" target="_blank"> (Association for Computational Linguistics, Stroudsburg, PA, USA, 2014). doi:</a></span><span><a href="http://dx.doi.org/10.3115/v1/d14-1066" rel="noopener noreferrer" target="_blank">10.3115/v1/d14-1066</a></span><span><a href="http://paperpile.com/b/coPcdt/NiSK" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>16. </span><span><a href="http://paperpile.com/b/coPcdt/GzNg" rel="noopener noreferrer" target="_blank">Wen, Z., Lu, X. H. &amp; Reddy, S. MeDAL: Medical abbreviation disambiguation dataset for natural language understanding pretraining. in </a></span><span><a href="http://paperpile.com/b/coPcdt/GzNg" rel="noopener noreferrer" target="_blank">Proceedings of the 3rd Clinical Natural Language Processing Workshop</a></span><span><a href="http://paperpile.com/b/coPcdt/GzNg" rel="noopener noreferrer" target="_blank"> (Association for Computational Linguistics, Stroudsburg, PA, USA, 2020). doi:</a></span><span><a href="http://dx.doi.org/10.18653/v1/2020.clinicalnlp-1.15" rel="noopener noreferrer" target="_blank">10.18653/v1/2020.clinicalnlp-1.15</a></span><span><a href="http://paperpile.com/b/coPcdt/GzNg" rel="noopener noreferrer" target="_blank">.</a></span></p><p><span>17. </span><span><a href="http://paperpile.com/b/coPcdt/VetX" rel="noopener noreferrer" target="_blank">Shi, W. </a></span><span><a href="http://paperpile.com/b/coPcdt/VetX" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/VetX" rel="noopener noreferrer" target="_blank"> Detecting pretraining data from large language models. </a></span><span><a href="http://paperpile.com/b/coPcdt/VetX" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/VetX" rel="noopener noreferrer" target="_blank"> (2023).</a></span></p><p><span>18. </span><span><a href="http://paperpile.com/b/coPcdt/eorr" rel="noopener noreferrer" target="_blank">Xu, R., Wang, Z., Fan, R.-Z. &amp; Liu, P. Benchmarking benchmark leakage in Large Language Models. </a></span><span><a href="http://paperpile.com/b/coPcdt/eorr" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/eorr" rel="noopener noreferrer" target="_blank"> (2024).</a></span></p><p><span>19. </span><span><a href="http://paperpile.com/b/coPcdt/ic2s" rel="noopener noreferrer" target="_blank">Zhou, K. </a></span><span><a href="http://paperpile.com/b/coPcdt/ic2s" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/ic2s" rel="noopener noreferrer" target="_blank"> Don’t make your LLM an evaluation benchmark cheater. </a></span><span><a href="http://paperpile.com/b/coPcdt/ic2s" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/ic2s" rel="noopener noreferrer" target="_blank"> (2023).</a></span></p><p><span>20. </span><span><a href="http://paperpile.com/b/coPcdt/o7lT" rel="noopener noreferrer" target="_blank">Kojima, T., Gu, S. S., Reid, M., Matsuo, Y. &amp; Iwasawa, Y. Large Language Models are Zero-Shot Reasoners. </a></span><span><a href="http://paperpile.com/b/coPcdt/o7lT" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/o7lT" rel="noopener noreferrer" target="_blank"> (2022).</a></span></p><p><span>21. </span><span><a href="http://paperpile.com/b/coPcdt/i7v8" rel="noopener noreferrer" target="_blank">Srivastava, S. </a></span><span><a href="http://paperpile.com/b/coPcdt/i7v8" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/i7v8" rel="noopener noreferrer" target="_blank"> Functional benchmarks for robust evaluation of reasoning performance, and the reasoning gap. </a></span><span><a href="http://paperpile.com/b/coPcdt/i7v8" rel="noopener noreferrer" target="_blank">arXiv [cs.AI]</a></span><span><a href="http://paperpile.com/b/coPcdt/i7v8" rel="noopener noreferrer" target="_blank"> (2024).</a></span></p><p><span>22. </span><span><a href="http://paperpile.com/b/coPcdt/7Z0s" rel="noopener noreferrer" target="_blank">Lu, S., Bigoulaeva, I., Sachdeva, R., Tayyar Madabushi, H. &amp; Gurevych, I. Are emergent abilities in large language models just in-context learning? in </a></span><span><a href="http://paperpile.com/b/coPcdt/7Z0s" rel="noopener noreferrer" target="_blank">Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</a></span><span><a href="http://paperpile.com/b/coPcdt/7Z0s" rel="noopener noreferrer" target="_blank"> 5098–5139 (Association for Computational Linguistics, Stroudsburg, PA, USA, 2024).</a></span></p><p><span>23. </span><span><a href="http://paperpile.com/b/coPcdt/UVGC" rel="noopener noreferrer" target="_blank">Magnusson, I. </a></span><span><a href="http://paperpile.com/b/coPcdt/UVGC" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/UVGC" rel="noopener noreferrer" target="_blank"> Paloma: A benchmark for evaluating language model fit. </a></span><span><a href="http://paperpile.com/b/coPcdt/UVGC" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/UVGC" rel="noopener noreferrer" target="_blank"> (2023).</a></span></p><p><span>24. </span><span><a href="http://paperpile.com/b/coPcdt/Z1jA" rel="noopener noreferrer" target="_blank">Zhang, H. </a></span><span><a href="http://paperpile.com/b/coPcdt/Z1jA" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/Z1jA" rel="noopener noreferrer" target="_blank"> A careful examination of large language model performance on grade school arithmetic. </a></span><span><a href="http://paperpile.com/b/coPcdt/Z1jA" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/Z1jA" rel="noopener noreferrer" target="_blank"> (2024).</a></span></p><p><span>25. </span><span><a href="http://paperpile.com/b/coPcdt/SrkJ" rel="noopener noreferrer" target="_blank">Zack, T. </a></span><span><a href="http://paperpile.com/b/coPcdt/SrkJ" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/SrkJ" rel="noopener noreferrer" target="_blank"> Assessing the potential of GPT-4 to perpetuate racial and gender biases in health care: a model evaluation study. </a></span><span><a href="http://paperpile.com/b/coPcdt/SrkJ" rel="noopener noreferrer" target="_blank">Lancet Digit. Health</a></span><span><a href="http://paperpile.com/b/coPcdt/SrkJ" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/SrkJ" rel="noopener noreferrer" target="_blank">6</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/SrkJ" rel="noopener noreferrer" target="_blank">, e12–e22 (2024).</a></span></p><p><span>26. </span><span><a href="http://paperpile.com/b/coPcdt/X0L4" rel="noopener noreferrer" target="_blank">Chen, S. </a></span><span><a href="http://paperpile.com/b/coPcdt/X0L4" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/X0L4" rel="noopener noreferrer" target="_blank"> Cross-Care: Assessing the healthcare implications of pre-training data on language model bias. </a></span><span><a href="http://paperpile.com/b/coPcdt/X0L4" rel="noopener noreferrer" target="_blank">Neural Inf Process Syst</a></span><span><a href="http://paperpile.com/b/coPcdt/X0L4" rel="noopener noreferrer" target="_blank"> </a></span><span><a href="http://paperpile.com/b/coPcdt/X0L4" rel="noopener noreferrer" target="_blank">abs/2405.05506</a></span><span><a href="http://paperpile.com/b/coPcdt/X0L4" rel="noopener noreferrer" target="_blank">, 23756–23795 (2024).</a></span></p><p><span>27. </span><span><a href="http://paperpile.com/b/coPcdt/RImu" rel="noopener noreferrer" target="_blank">Guevara, M. </a></span><span><a href="http://paperpile.com/b/coPcdt/RImu" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/RImu" rel="noopener noreferrer" target="_blank"> Large language models to identify social determinants of health in electronic health records. </a></span><span><a href="http://paperpile.com/b/coPcdt/RImu" rel="noopener noreferrer" target="_blank">NPJ Digit. Med.</a></span><span><a href="http://paperpile.com/b/coPcdt/RImu" rel="noopener noreferrer" target="_blank"> </a></span><span><sup class="citation-ref"><a class="citation-link" href="http://paperpile.com/b/coPcdt/RImu" rel="noopener noreferrer" target="_blank">7</a></sup></span><span><a href="http://paperpile.com/b/coPcdt/RImu" rel="noopener noreferrer" target="_blank">, 6 (2024).</a></span></p><p><span>28. </span><span><a href="http://paperpile.com/b/coPcdt/TVaD" rel="noopener noreferrer" target="_blank">Ness, R. O. </a></span><span><a href="http://paperpile.com/b/coPcdt/TVaD" rel="noopener noreferrer" target="_blank">et al.</a></span><span><a href="http://paperpile.com/b/coPcdt/TVaD" rel="noopener noreferrer" target="_blank"> MedFuzz: Exploring the robustness of large language models in medical question answering. </a></span><span><a href="http://paperpile.com/b/coPcdt/TVaD" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/TVaD" rel="noopener noreferrer" target="_blank"> (2024).</a></span></p><p><span>29. </span><span><a href="http://paperpile.com/b/coPcdt/x6hn" rel="noopener noreferrer" target="_blank">Liu, J., Min, S., Zettlemoyer, L., Choi, Y. &amp; Hajishirzi, H. Infini-gram: Scaling unbounded n-gram language models to a trillion tokens. </a></span><span><a href="http://paperpile.com/b/coPcdt/x6hn" rel="noopener noreferrer" target="_blank">arXiv [cs.CL]</a></span><span><a href="http://paperpile.com/b/coPcdt/x6hn" rel="noopener noreferrer" target="_blank"> (2024).</a></span></p><figure class="chapter-figure"><img alt="Thesis figure" decoding="async" loading="lazy" src="thesis-assets/images/image34.png" title=""/></figure>